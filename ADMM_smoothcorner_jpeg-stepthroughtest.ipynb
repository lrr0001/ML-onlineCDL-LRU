{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 7, 1, 48)\n",
      "(5, 5, 48, 64)\n",
      "(1, 7, 7, 1, 48)\n",
      "(1, 5, 5, 48, 64)\n"
     ]
    }
   ],
   "source": [
    "import ML_ADMM_jpeg_corner_smoothing as mlcsc\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle as pkl\n",
    "import jpeg_related_functions as jrf\n",
    "import numpy as np\n",
    "\n",
    "rho = 1.\n",
    "noi = 32\n",
    "alpha_init = 1.5\n",
    "blkSmthCoef = 1.0\n",
    "pklfile = 'ML_LRA_checkpoint_epoch_128.ckpt.pkl'\n",
    "num_of_epochs = 1\n",
    "#steps_per_epoch = 0\n",
    "\n",
    "rho = 1.\n",
    "noi = 32\n",
    "alpha_init = 1.5\n",
    "blkSmthCoef = 1.0\n",
    "n_components = 4\n",
    "cmplxdtype = tf.complex128 # This should really be elsewhere.\n",
    "batch_size = 1\n",
    "#steps_per_epoch = 4\n",
    "step_size = 0.01\n",
    "#num_of_epochs = 2\n",
    "\n",
    "#   ******** BASE NAMES AND DIRECTORIES  ********\n",
    "modelname = 'ML_ADMM_'\n",
    "databasename = 'BSDS500/'\n",
    "#databasename = 'simpleTest/'\n",
    "experimentname = 'experiment1/'\n",
    "\n",
    "#   ******** DEPENDENT NAMES AND DIRECTORIES\n",
    "experimentpath = 'data/experiment/' + databasename + experimentname\n",
    "checkpointfilename = modelname + 'checkpoint_epoch_{epoch:02d}.ckpt'\n",
    "timesname = 'times/' + modelname + 'rho' + str(rho) + '_iter' + str(noi) + '_times.pkl'\n",
    "modelfilename = modelname + 'initial_model.ckpt'\n",
    "\n",
    "#   ******** DATA AND EXPERIMENT PARAMETERS ********\n",
    "fid = open(experimentpath + 'problem_param.pckl','rb')\n",
    "problem_param = pkl.load(fid)\n",
    "fid.close()\n",
    "data_param = problem_param['data_param']\n",
    "targetSz = data_param['target_size']\n",
    "qY = data_param['qY']\n",
    "qUV = data_param['qUV']\n",
    "strides = problem_param['stride']\n",
    "fltrSz = problem_param['fltrSz']\n",
    "real_dtype = data_param['dtype']\n",
    "#noi = problem_param['noi']\n",
    "noL = problem_param['noL']\n",
    "noc = problem_param['noc']\n",
    "datapath = problem_param['datapath']\n",
    "trainfile = problem_param['trainfile']\n",
    "valfile = problem_param['valfile']\n",
    "padding = data_param['padding']\n",
    "fid = open(experimentpath + pklfile,'rb')\n",
    "mu_init = pkl.load(fid)\n",
    "D = pkl.load(fid)\n",
    "b_init = pkl.load(fid)\n",
    "fid.close()\n",
    "\n",
    "#   ******** CROPPING AND PADDING ********\n",
    "cropAndMerge = mlcsc.CropPadObject(targetSz,strides,[np.asarray(ks) for ks in fltrSz],real_dtype,blkSz = (8,8))\n",
    "paddingTuple = cropAndMerge.paddingTuple\n",
    "fftSz = cropAndMerge.get_fft_size(targetSz,strides)\n",
    "paddingDiff = ((padding[0][0] - paddingTuple[0][0],padding[0][1] - paddingTuple[0][1]),(padding[1][0] - paddingTuple[1][0],padding[1][1] -  paddingTuple[1][1]))\n",
    "assert(paddingDiff[0][0] >= 0)\n",
    "assert(paddingDiff[0][1] >= 0)\n",
    "assert(paddingDiff[1][0] >= 0)\n",
    "assert(paddingDiff[1][1] >= 0)\n",
    "    \n",
    "#   ******** SETUP LOADING TFRECORD ********\n",
    "startr = paddingDiff[0][0]\n",
    "startc = paddingDiff[1][0]\n",
    "endr = targetSz[0] + padding[0][0] + padding[0][1] - paddingDiff[0][1]\n",
    "endc = targetSz[1] + padding[1][0] + padding[1][1] - paddingDiff[1][1]\n",
    "example_structure = {'highpass': tf.io.FixedLenFeature([], tf.string), 'lowpass': tf.io.FixedLenFeature([], tf.string), 'compressed': tf.io.FixedLenFeature([], tf.string),'raw': tf.io.FixedLenFeature([], tf.string)}\n",
    "\n",
    "def restore_double(x):\n",
    "    return tf.io.parse_tensor(x,real_dtype)\n",
    "\n",
    "class RGB2Y(tf.keras.layers.Layer):\n",
    "    def __init__(self,*args,**kwargs):\n",
    "        super().__init__(*args,**kwargs)\n",
    "        self.rgb2yuv = jrf.RGB2YUV(dtype = self.dtype)\n",
    "    def call(self,inputs):\n",
    "        s_YUV = self.rgb2yuv(inputs)\n",
    "        return s_YUV[slice(None),slice(None),slice(0,1)]\n",
    "\n",
    "rgb2y = RGB2Y(dtype=real_dtype)\n",
    "\n",
    "def _parse_image_function(example_proto):\n",
    "    x = tf.io.parse_single_example(example_proto, example_structure)\n",
    "    highpass = restore_double(x['highpass'])\n",
    "    lowpass = restore_double(x['lowpass'])\n",
    "    #return ((highpass[slice(startr,endr),slice(startc,endc),slice(None)],lowpass[slice(startr,endr),slice(startc,endc),slice(None)],restore_double(x['compressed'])),rgb2y(restore_double(x['raw'])))\n",
    "    return ((highpass[slice(startr,endr),slice(startc,endc),slice(None)],lowpass[slice(startr,endr),slice(startc,endc),slice(None)],restore_double(x['compressed'])),restore_double(x['raw']))\n",
    "\n",
    "raw_dataset = tf.data.TFRecordDataset([datapath + valfile])\n",
    "dataset = raw_dataset.map(_parse_image_function)\n",
    "dataset_batch = dataset.batch(batch_size)\n",
    "\n",
    "\n",
    "\n",
    "print(D[0].shape)\n",
    "print(D[1].shape)\n",
    "print(problem_param['D'][0].shape)\n",
    "print(problem_param['D'][1].shape)\n",
    "\n",
    "#   ******** BUILD MODEL ********\n",
    "CSC = mlcsc.MultiLayerCSC_JPEGY(rho,alpha_init,mu_init,b_init,blkSmthCoef,qY,cropAndMerge,fftSz,strides,[tf.expand_dims(D_temp,axis=0) for D_temp in D],n_components,noi,noL,cmplxdtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for (x,y) in dataset_batch:\n",
    "    x_input = x\n",
    "    x_output = y\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = CSC.preprocess(x_input)\n",
    "y,u,By,negC,itstats = CSC.init_vars(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x,Ax = CSC.xstep(y,u,By,negC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "representation error:  tf.Tensor(5.159849654548241, shape=(), dtype=float64)\n",
      "coefficient_penalty:  tf.Tensor(0.010930505507348743, shape=(), dtype=float64)\n",
      "constraint penalty:  tf.Tensor(10.99363157132818, shape=(), dtype=float64)\n",
      "u correction:  tf.Tensor(31.3474920182214, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "augLangBefore = CSC.evaluateLagrangian(s,x,y,u,Ax,By,negC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "uhalf = CSC.relax(u,Ax,By,negC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "representation error:  tf.Tensor(5.159849654548241, shape=(), dtype=float64)\n",
      "coefficient_penalty:  tf.Tensor(0.010930505507348743, shape=(), dtype=float64)\n",
      "constraint penalty:  tf.Tensor(7.5514846077502735, shape=(), dtype=float64)\n",
      "u correction:  tf.Tensor(18.92563404148522, shape=(), dtype=float64)\n",
      "Augmented Lagrangian Increase:  tf.Tensor(8.979711013158273, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "augLangAfter = CSC.evaluateLagrangian(s,x,y,uhalf,Ax,By,negC)\n",
    "print('Augmented Lagrangian Increase: ',augLangAfter - augLangBefore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "representation error:  tf.Tensor(5.159849654548241, shape=(), dtype=float64)\n",
      "coefficient_penalty:  tf.Tensor(0.010930505507348743, shape=(), dtype=float64)\n",
      "constraint penalty:  tf.Tensor(7.5514846077502735, shape=(), dtype=float64)\n",
      "u correction:  tf.Tensor(18.92563404148522, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "AugLangBefore = CSC.evaluateLagrangian(s,x,y,uhalf,Ax,By,negC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y,By = CSC.ystep(x,uhalf,Ax,negC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "representation error:  tf.Tensor(5.076108652130519, shape=(), dtype=float64)\n",
      "coefficient_penalty:  tf.Tensor(0.01173836921997972, shape=(), dtype=float64)\n",
      "constraint penalty:  tf.Tensor(7.53088801117616, shape=(), dtype=float64)\n",
      "u correction:  tf.Tensor(18.92563404148522, shape=(), dtype=float64)\n",
      "Augmented Lagrangian Decrease:  tf.Tensor(-8.876181277879066, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "augLangAfter = CSC.evaluateLagrangian(s,x,y,uhalf,Ax,By,negC)\n",
    "print('Augmented Lagrangian Decrease: ',augLangBefore - augLangAfter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "representation error:  tf.Tensor(5.076108652130519, shape=(), dtype=float64)\n",
      "coefficient_penalty:  tf.Tensor(0.01173836921997972, shape=(), dtype=float64)\n",
      "constraint penalty:  tf.Tensor(7.53088801117616, shape=(), dtype=float64)\n",
      "u correction:  tf.Tensor(18.92563404148522, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "AugLangBefore = CSC.evaluateLagrangian(s,x,y,uhalf,Ax,By,negC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u = CSC.ustep(uhalf,Ax,By,negC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "representation error:  tf.Tensor(5.076108652130519, shape=(), dtype=float64)\n",
      "coefficient_penalty:  tf.Tensor(0.01173836921997972, shape=(), dtype=float64)\n",
      "constraint penalty:  tf.Tensor(14.014266696174698, shape=(), dtype=float64)\n",
      "u correction:  tf.Tensor(7.53088801117616, shape=(), dtype=float64)\n",
      "Augmented Lagrangian Increase:  tf.Tensor(26.754305993186666, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "augLangAfter = CSC.evaluateLagrangian(s,x,y,u,Ax,By,negC)\n",
    "print('Augmented Lagrangian Increase: ',augLangAfter - augLangBefore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "representation error:  tf.Tensor(5.076108652130519, shape=(), dtype=float64)\n",
      "coefficient_penalty:  tf.Tensor(0.01173836921997972, shape=(), dtype=float64)\n",
      "constraint penalty:  tf.Tensor(14.014266696174698, shape=(), dtype=float64)\n",
      "u correction:  tf.Tensor(7.53088801117616, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "AugLangBefore = CSC.evaluateLagrangian(s,x,y,u,Ax,By,negC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x,Ax = CSC.xstep(y,u,By,negC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "representation error:  tf.Tensor(0.5594243747965242, shape=(), dtype=float64)\n",
      "coefficient_penalty:  tf.Tensor(0.01173836921997972, shape=(), dtype=float64)\n",
      "constraint penalty:  tf.Tensor(4.731309043576802, shape=(), dtype=float64)\n",
      "u correction:  tf.Tensor(7.53088801117616, shape=(), dtype=float64)\n",
      "Augmented Lagrangian Decrease:  tf.Tensor(-12.954664063254775, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "augLangAfter = CSC.evaluateLagrangian(s,x,y,u,Ax,By,negC)\n",
    "print('Augmented Lagrangian Decrease: ',augLangBefore - augLangAfter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
