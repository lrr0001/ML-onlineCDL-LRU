{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import jpeg_related_functions as jrf\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "jpeg_quality = 25\n",
    "rho = 1.\n",
    "alpha = 1.5\n",
    "noi = 20\n",
    "lmbda = 0.1\n",
    "dtype = 'float64'\n",
    "img_ind = 7\n",
    "YUV2RGB = jrf.YUV2RGB(dtype= tf.as_dtype(dtype))\n",
    "def yuv2rgb(yuv_tensor):\n",
    "    rgb_tensor = tf.squeeze(YUV2RGB(yuv_tensor),axis = 0)\n",
    "    rgb_tensor = tf.where(rgb_tensor > 1.,1.,rgb_tensor)\n",
    "    rgb_tensor = tf.where(rgb_tensor < 0.,0.,rgb_tensor)\n",
    "    return (255*np.asarray(rgb_tensor)).astype('uint8')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain quantization matrices from chosen quality factor\n",
    "import PIL\n",
    "import PIL.Image\n",
    "randImgPath = 'data/scratchwork/example/randImg.jpeg'\n",
    "randimg = np.random.randint(0,256,size=(32,32,3))\n",
    "encoded_jpeg = tf.image.encode_jpeg(randimg,quality = jpeg_quality)\n",
    "tf.io.write_file(randImgPath,encoded_jpeg)\n",
    "loadedRandImg = PIL.Image.open(randImgPath)\n",
    "qY = np.asarray(loadedRandImg.quantization[0]).astype('uint8')\n",
    "qUV = np.asarray(loadedRandImg.quantization[1]).astype('uint8')\n",
    "qY = qY.astype(dtype)/255.\n",
    "qUV = qUV.astype(dtype)/255.\n",
    "import os\n",
    "os.remove(randImgPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fftSz1 = (480,320)\n",
    "fftSz2 = (320,480)\n",
    "smooth_jpeg1 = jrf.Smooth_JPEG(rho,alpha,noi,qY,qUV,lmbda,fftSz1,dtype=dtype)\n",
    "smooth_jpeg2 = jrf.Smooth_JPEG(rho,alpha,noi,qY,qUV,lmbda,fftSz2,dtype=dtype)\n",
    "Yoffset = tf.one_hot([[[0]]],64,tf.cast(32.,dtype = dtype),tf.cast(0.,dtype= dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataPath = 'data/original/simpleTest/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatype = 'train/'\n",
    "filelist = os.listdir(dataPath + datatype)\n",
    "ii = 0\n",
    "for filename in filelist:\n",
    "    if ii == img_ind:\n",
    "        break\n",
    "    ii += 1\n",
    "loadedPILImg = PIL.Image.open(dataPath + datatype + filename)\n",
    "loadedImg = np.asarray(loadedPILImg).astype(dtype)/255.\n",
    "loadedImgShape = loadedImg.shape\n",
    "# crop out a row and a column\n",
    "loadedImg = loadedImg[slice(0,loadedImgShape[0] - (loadedImgShape[0] % 8)),slice(0,loadedImgShape[1] - (loadedImgShape[1] % 8)),slice(None)]\n",
    "if loadedImgShape[0] - (loadedImgShape[0] % 8) == 480 and loadedImgShape[1] - (loadedImgShape[1] % 8) == 320:\n",
    "    # compressedImg = smooth_jpeg1.Wt(jrf.threeChannelQuantize(smooth_jpeg1.W(tf.reshape(loadedImg,(1,) + loadedImg.shape)),qY,qUV,Yoffset))\n",
    "    lowpass,compressedImg = smooth_jpeg1(tf.reshape(loadedImg,(1,) + loadedImg.shape))\n",
    "elif loadedImgShape[0] - (loadedImgShape[0] % 8) == 320 and loadedImgShape[1] - (loadedImgShape[1] % 8) == 480:\n",
    "    #compressedImg = smooth_jpeg2.Wt(jrf.threeChannelQuantize(smooth_jpeg2.W(tf.reshape(loadedImg,(1,) + loadedImg.shape)),qY,qUV,Yoffset))\n",
    "    lowpass,compressedImg = smooth_jpeg2(tf.reshape(loadedImg,(1,) + loadedImg.shape))\n",
    "else:\n",
    "    raise ValueError('Unexpected Shape!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f65cc06c320>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f65b0593400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "np_img = np.asarray(loadedPILImg).astype('uint8')\n",
    "plt.imshow(np_img[120:152,140:172,:])\n",
    "#Yoffset = tf.one_hot([[[0]]],64,tf.cast(32.,tf.as_dtype('float64')),tf.cast(0.,tf.as_dtype('float64')))\n",
    "#print(np.amax(np_img))\n",
    "#print(np.amin(np_img))\n",
    "#np_img_float = np_img.astype('float64')/255.\n",
    "#tf_img_float = tf.expand_dims(np_img_float,axis=0)\n",
    "#yuv_img = jrf.RGB2YUV(dtype=tf.as_dtype('float64'))(tf_img_float)\n",
    "#rgb_img = jrf.YUV2RGB(dtype=tf.as_dtype('float64'))(smooth_jpeg2.Wt(smooth_jpeg2.W(yuv_img)))\n",
    "#np_img = np.asarray(255.*tf.squeeze(rgb_img,axis=0)).astype('uint8')\n",
    "#plt.imshow(np_img)\n",
    "#quantized_img = jrf.threeChannelQuantize(smooth_jpeg2.W(yuv_img),qY,qUV,Yoffset)\n",
    "#rgb_img = jrf.YUV2RGB(dtype=tf.as_dtype('float64'))(smooth_jpeg2.Wt(quantized_img))\n",
    "#np_img = np.asarray(255.*tf.squeeze(rgb_img,axis=0)).astype('uint8')\n",
    "#plt.imshow(np_img)\n",
    "#quantized_yuv_img = smooth_jpeg2.Wt(quantized_img)\n",
    "#plt.imshow(yuv2rgb(quantized_yuv_img))\n",
    "#quantized_img = jrf.threeChannelQuantize(smooth_jpeg2.W(tf.expand_dims(jrf.RGB2YUV()(np.asarray(loadedPILImg).astype('float64')),axis=0)),qY,qUV,Yoffset)\n",
    "#plt.imshow(np.asarray(jrf.YUV2RGB()(tf.squeeze(smooth_jpeg2.Wt(quantized_img),axis=0))).astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 320, 3)\n",
      "255\n",
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f65cc060ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ci = yuv2rgb(compressedImg)\n",
    "plt.imshow(ci[120:152,140:172,:])\n",
    "print(ci.shape)\n",
    "print(np.amax(ci))\n",
    "print(np.amin(ci))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f66204fd438>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f65b056b9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lp = yuv2rgb(lowpass)\n",
    "plt.imshow(lp[120:152,140:172,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.20425793568312403, shape=(), dtype=float64)\n",
      "tf.Tensor(0.2088076502360203, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "my_raw = tf.expand_dims(tf.cast(yuv2rgb(tf.expand_dims(loadedImg,axis=0)),'float64')/255,axis=0)\n",
    "my_lp = tf.expand_dims(tf.cast(yuv2rgb(lowpass),'float64')/255,axis=0)\n",
    "my_cmprss = tf.expand_dims(tf.cast(yuv2rgb(compressedImg),'float64')/255,axis=0)\n",
    "print(tf.reduce_mean(tf.keras.losses.mean_squared_error(my_raw,my_lp)))\n",
    "print(tf.reduce_mean(tf.keras.losses.mean_squared_error(my_raw,my_cmprss)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import jpeg_related_functions as jrf\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "qY = np.array([[16, 11, 10, 16, 24, 40, 51, 61],\n",
    "              [12, 12, 14, 19, 26, 58, 60, 55],\n",
    "              [14, 13, 16, 24, 40, 57, 69, 56],\n",
    "              [14, 17, 22, 29, 51, 87, 80, 62],\n",
    "              [18, 22, 37, 56, 68, 109, 103, 77],\n",
    "              [24, 35, 55, 64, 81, 104, 113, 92],\n",
    "              [49, 64, 78, 87, 103, 121, 120, 101],\n",
    "              [72, 92, 95, 98, 112, 100, 103, 99]])\n",
    "qY = qY.astype('float64')/255.\n",
    "qUV = qY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "lmbda = 4.\n",
    "rho = 0.1\n",
    "alpha = 1.\n",
    "noi = 10\n",
    "image = Image.open(\"20190728_matthewdruincom_SLE_0033.jpg\")\n",
    "s = np.asarray(image).astype('float64')/255.\n",
    "s = s[slice(0,1600),slice(0,2800),slice(None)]\n",
    "s = np.reshape(s,(1,) + s.shape)\n",
    "fftSz = s.shape[1:3]\n",
    "smooth_jpeg = jrf.Smooth_JPEG(rho,alpha,noi,qY,qUV,lmbda,fftSz,dtype=tf.float64)\n",
    "#y,u,By,negC = smooth_jpeg.init_vars(s)\n",
    "#outputs = smooth_jpeg(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs = smooth_jpeg(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "highpass,lowpass = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x,y,u = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2.039646333059423, shape=(), dtype=float64)\n",
      "tf.Tensor(2.1151680018556487, shape=(), dtype=float64)\n",
      "tf.Tensor(0.8840874549355658, shape=(), dtype=float64)\n",
      "tf.Tensor(0.8297288644681492, shape=(), dtype=float64)\n",
      "tf.Tensor(1.3342601848054017, shape=(), dtype=float64)\n",
      "tf.Tensor(1.3342601848058462, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(tf.math.reduce_max(x))\n",
    "print(tf.math.reduce_max(y))\n",
    "print(tf.math.reduce_min(x))\n",
    "print(tf.math.reduce_min(y))\n",
    "print(tf.math.reduce_mean(x))\n",
    "print(tf.math.reduce_mean(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_init,u_init,By_init,negC,itstats = smooth_jpeg.init_vars(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.1837382249200323, shape=(), dtype=float64)\n",
      "tf.Tensor(-0.21214950634511898, shape=(), dtype=float64)\n",
      "tf.Tensor(0.3588879588149992, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(tf.reduce_max(y_init))\n",
    "print(tf.reduce_min(y_init))\n",
    "print(tf.reduce_mean(y_init))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.1837382249200323, shape=(), dtype=float64)\n",
      "tf.Tensor(-0.21214950634511898, shape=(), dtype=float64)\n",
      "tf.Tensor(0.3588879588149992, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(tf.reduce_max(smooth_jpeg.Wt(negC)))\n",
    "print(tf.reduce_min(smooth_jpeg.Wt(negC)))\n",
    "print(tf.reduce_mean(smooth_jpeg.Wt(negC)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.1837382249200323, shape=(), dtype=float64)\n",
      "tf.Tensor(-0.21214950634511898, shape=(), dtype=float64)\n",
      "tf.Tensor(0.3588879588149992, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(tf.reduce_max(smooth_jpeg.Wt(By_init)))\n",
    "print(tf.reduce_min(smooth_jpeg.Wt(By_init)))\n",
    "print(tf.reduce_mean(smooth_jpeg.Wt(By_init)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x,Ax = smooth_jpeg.xstep(y_init,u_init,By_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.0390829950833103, shape=(), dtype=float64)\n",
      "tf.Tensor(-0.03794457125802076, shape=(), dtype=float64)\n",
      "tf.Tensor(0.3596462283896552, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(tf.reduce_max(x))\n",
    "print(tf.reduce_min(x))\n",
    "print(tf.reduce_mean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AxplusC = smooth_jpeg.relax(Ax,By_init,negC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.0, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(tf.reduce_max(AxplusC[0] + negC[0]))\n",
    "print(tf.reduce_min(AxplusC[0] + negC[0]))\n",
    "print(tf.reduce_max(AxplusC[1] + negC[1]))\n",
    "print(tf.reduce_min(AxplusC[1] + negC[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y,By = smooth_jpeg.ystep(x,u_init,AxplusC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.095376683391678, shape=(), dtype=float64)\n",
      "tf.Tensor(1.1340443007804173, shape=(), dtype=float64)\n",
      "tf.Tensor(-0.07691133243708641, shape=(), dtype=float64)\n",
      "tf.Tensor(-0.11176080134176089, shape=(), dtype=float64)\n",
      "tf.Tensor(0.3598486538373756, shape=(), dtype=float64)\n",
      "tf.Tensor(0.3601107598790794, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(tf.reduce_max(y))\n",
    "print(tf.reduce_max(smooth_jpeg.Wt(By)))\n",
    "print(tf.reduce_min(y))\n",
    "print(tf.reduce_min(smooth_jpeg.Wt(By)))\n",
    "print(tf.reduce_mean(y))\n",
    "print(tf.reduce_mean(smooth_jpeg.Wt(By)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u = smooth_jpeg.ustep(u_init,AxplusC,By)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x,Ax = smooth_jpeg.xstep(y,u,By)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AxplusC = smooth_jpeg.relax(Ax,By,negC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y,By = smooth_jpeg.ystep(x,u,AxplusC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u = smooth_jpeg.ustep(u,AxplusC,By)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x,Ax = smooth_jpeg.xstep(s,u_init,By_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1600, 2800, 3)\n",
      "(1, 1600, 2800, 3)\n",
      "tf.Tensor(1.0, shape=(), dtype=float64)\n",
      "tf.Tensor(1.0000000000006473, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0, shape=(), dtype=float64)\n",
      "tf.Tensor(-4.956660487039716e-13, shape=(), dtype=float64)\n",
      "tf.Tensor(0.3588261461251168, shape=(), dtype=float64)\n",
      "tf.Tensor(0.3588261461249889, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "import transforms as transf\n",
    "fft = transf.fft2d_multichannel(s.shape[1:3])\n",
    "ifft = transf.ifft2d_multichannel(s.shape[1:3])\n",
    "s_still = ifft(fft(s))\n",
    "print(s.shape)\n",
    "print(s_still.shape)\n",
    "\n",
    "print(tf.reduce_max(s))\n",
    "print(tf.reduce_max(s_still))\n",
    "print(tf.reduce_min(s))\n",
    "print(tf.reduce_min(s_still))\n",
    "print(tf.reduce_mean(s))\n",
    "print(tf.reduce_mean(s_still))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_new = tf.where(x < 0,0.,x)\n",
    "x_new = tf.where(x_new > 1.0,1.0,x_new)\n",
    "smoothImage = Image.fromarray((255.*np.asarray(tf.reshape(x_new,x_new.shape[1:]))).astype('uint8'),'RGB')\n",
    "smoothImage.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_new = tf.where(highpass < 0.,0.,highpass)\n",
    "y_new = tf.where(y_new > 1.0,1.0,y_new)\n",
    "smoothImage = Image.fromarray((255.*np.asarray(tf.reshape(y_new,y_new.shape[1:]))).astype('uint8'),'RGB')\n",
    "smoothImage.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lowpass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.2570130949512816, shape=(), dtype=float64)\n",
      "tf.Tensor(0.2570130949512816, shape=(), dtype=float64)\n",
      "tf.Tensor(0.04323715026838358, shape=(), dtype=float64)\n",
      "tf.Tensor(0.04323715026838358, shape=(), dtype=float64)\n",
      "tf.Tensor(0.07887996586296282, shape=(), dtype=float64)\n",
      "tf.Tensor(0.07887996586296282, shape=(), dtype=float64)\n",
      "tf.Tensor(-0.03274309150125233, shape=(), dtype=float64)\n",
      "tf.Tensor(-0.03274309150125233, shape=(), dtype=float64)\n",
      "tf.Tensor(-0.033754955995817404, shape=(), dtype=float64)\n",
      "tf.Tensor(-0.033754955995817404, shape=(), dtype=float64)\n",
      "tf.Tensor(-0.05825989553795034, shape=(), dtype=float64)\n",
      "tf.Tensor(-0.05825989553795034, shape=(), dtype=float64)\n",
      "tf.Tensor(0.06513041623543925, shape=(), dtype=float64)\n",
      "tf.Tensor(0.06513041623543925, shape=(), dtype=float64)\n",
      "tf.Tensor(-0.0011787114132774982, shape=(), dtype=float64)\n",
      "tf.Tensor(-0.0011787114132774982, shape=(), dtype=float64)\n",
      "tf.Tensor(0.007870027512006482, shape=(), dtype=float64)\n",
      "tf.Tensor(0.007870027512006482, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "wtBy_yuv = tf.image.rgb_to_yuv(wtBy)\n",
    "wtBY_y,wtBY_u,wtBY_v = tf.split(wtBy_yuv,axis=3,num_or_size_splits=3)\n",
    "\n",
    "wtqwy = smooth_jpeg.Wt([smooth_jpeg.q*tf.math.round(smooth_jpeg.W(y)[channel]/smooth_jpeg.q) for channel in range(3)])\n",
    "wtqwy_yuv = tf.image.rgb_to_yuv(wtqwy)\n",
    "wtqwy_y,wtqwy_u,wtqwy_v = tf.split(wtqwy_yuv,axis=3,num_or_size_splits=3)\n",
    "\n",
    "print(tf.math.reduce_max(wtBY_y))\n",
    "print(tf.math.reduce_max(wtqwy_y))\n",
    "print(tf.math.reduce_max(wtBY_u))\n",
    "print(tf.math.reduce_max(wtqwy_u))\n",
    "print(tf.math.reduce_max(wtBY_v))\n",
    "print(tf.math.reduce_max(wtBY_v))\n",
    "print(tf.math.reduce_min(wtBY_y))\n",
    "print(tf.math.reduce_min(wtqwy_y))\n",
    "print(tf.math.reduce_min(wtBY_u))\n",
    "print(tf.math.reduce_min(wtqwy_u))\n",
    "print(tf.math.reduce_min(wtBY_v))\n",
    "print(tf.math.reduce_min(wtBY_v))\n",
    "print(tf.math.reduce_mean(wtBY_y))\n",
    "print(tf.math.reduce_mean(wtqwy_y))\n",
    "print(tf.math.reduce_mean(wtBY_u))\n",
    "print(tf.math.reduce_mean(wtqwy_u))\n",
    "print(tf.math.reduce_mean(wtBY_v))\n",
    "print(tf.math.reduce_mean(wtBY_v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lowpass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.cast(lowpass,tf.float32)\n",
    "x_small = x[slice(None),slice(0,256),slice(0,256),slice(None)]\n",
    "smoothImage = Image.fromarray(np.asarray(tf.reshape(x_small,x_small.shape[1:])),'RGB')\n",
    "smoothImage.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.92229486>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_max(x_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.8896151>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_min(x_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=1.0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_max(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_min(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_new,Ax_new = smooth_jpeg.xstep(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.9259259259265392>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_max(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=-4.566629576338341e-13>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_min(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lowpass = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lowpass = wtBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_new = tf.where(lowpass < 0,0.,lowpass)\n",
    "x_new = tf.where(x_new > 1.0,1.0,x_new)\n",
    "smoothImage = Image.fromarray((255.*np.asarray(tf.reshape(x_new,x_new.shape[1:]))).astype('uint8'),'RGB')\n",
    "smoothImage.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.025259007677445326, shape=(), dtype=float64)\n",
      "tf.Tensor(-0.004116784037421037, shape=(), dtype=float64)\n",
      "tf.Tensor(0.007235759263040731, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(tf.reduce_max(lowpass))\n",
    "print(tf.reduce_min(lowpass))\n",
    "print(tf.reduce_mean(lowpass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.5130693627046149>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_min(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.6106675396815834>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.7188945327525801>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_max(wtBy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.4095120582383085>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_min(wtBy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.5205163330596897>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(wtBy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 200, 350, 64])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smooth_jpeg.W(wtBy)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.613012462000272>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(smooth_jpeg.Wt([smooth_jpeg.q*tf.math.round(smooth_jpeg.W(y)[channel]/smooth_jpeg.q) for channel in range(3)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.09169928799980395>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_max(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.05429964236971775>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_min(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 1600, 2800, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smoothImage = Image.fromarray(np.asarray(tf.reshape(x_new,x_new.shape[1:]))*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "image = Image.open(\"20190728_matthewdruincom_SLE_0033.jpg\")\n",
    "#image = Image.open(\"20200202_matthewdruincom_SLW_0085.jpg\")\n",
    "#image.show()\n",
    "import numpy as np\n",
    "x_orig = np.asarray(image).astype('float64')\n",
    "\n",
    "x_batch = np.reshape(x_orig.astype('float64')/255.,(1,)+x_orig.shape)\n",
    "x_batch = x_batch[slice(None),slice(0,1600),slice(0,2800),slice(None)]\n",
    "x = (np.reshape(x_batch,x_batch.shape[1:])*255.).astype('uint8')\n",
    "x_orig = Image.fromarray(x)\n",
    "x_cmprss = tf.image.adjust_jpeg_quality(x,25)\n",
    "image_cmprss = Image.fromarray(np.asarray(x_cmprss),'RGB')\n",
    "image_cmprss.show()\n",
    "x_cmprss_batch = np.reshape(np.asarray(x_cmprss).astype('float64')/255.,(1,)+x_cmprss.shape)\n",
    "#x_cmprss_apprx = jrf.Linear_JPEG_Compression_Approx(x_cmprss_batch)(x_batch)\n",
    "#image_cmprss_apprx = Image.fromarray(np.asarray(x_cmprss_apprx*255).astype('uint8'),'RGB')\n",
    "#image_cmprss_apprx.show\n",
    "\n",
    "#y = jpeg_coef2rgb(rgb2jpeg_coef(x))\n",
    "#z = jpeg_coef2rgb(rgb2jpeg_coef(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1600, 2800, 3)\n",
      "(1, 1600, 2800, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_batch.shape)\n",
    "print(x_cmprss_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer rg_b2jpeg__coef_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer linear_jpeg__compression__approx is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_cmprss_apprx = jrf.Linear_JPEG_Compression_Approx(x_cmprss_batch,epsilon=1e-3)(x_batch)\n",
    "#print(tf.math.reduce_min(tf.where(jrf.Linear_JPEG_Compression_Approx(x_cmprss_batch).masky,1.0,0.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_cmprss_apprx = Image.fromarray(np.asarray(tf.reshape(x_cmprss_apprx,x_cmprss_apprx.shape[1:])*255).astype('uint8'),'RGB')\n",
    "image_cmprss_apprx.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.0698118, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.math.reduce_max(x_cmprss_apprx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.reduce_min(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.21713108, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.math.reduce_max(tf.math.abs(x - y)))\n",
    "print(tf.math.reduce_max(tf.math.abs(z - y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([5, 128, 128, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.22571766>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.4955484>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.one_hot(indices=[[[0]]],depth=64,on_value=2.,dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 1, 1, 64])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=2.0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
