{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import jpeg_related_functions as jrf\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "jpeg_quality = 25\n",
    "rho = 1.\n",
    "alpha = 1.5\n",
    "noi = 20\n",
    "lmbda = 0.1\n",
    "dtype = 'float64'\n",
    "img_ind = 3\n",
    "YUV2RGB = jrf.YUV2RGB(dtype= tf.as_dtype(dtype))\n",
    "def yuv2rgb(yuv_tensor):\n",
    "    rgb_tensor = tf.squeeze(YUV2RGB(yuv_tensor),axis = 0)\n",
    "    rgb_tensor = tf.where(rgb_tensor > 1.,1.,rgb_tensor)\n",
    "    rgb_tensor = tf.where(rgb_tensor < 0.,0.,rgb_tensor)\n",
    "    return (255*np.asarray(rgb_tensor)).astype('uint8')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain quantization matrices from chosen quality factor\n",
    "import PIL\n",
    "import PIL.Image\n",
    "randImgPath = 'data/scratchwork/example/randImg.jpeg'\n",
    "randimg = np.random.randint(0,256,size=(32,32,3))\n",
    "encoded_jpeg = tf.image.encode_jpeg(randimg,quality = jpeg_quality)\n",
    "tf.io.write_file(randImgPath,encoded_jpeg)\n",
    "loadedRandImg = PIL.Image.open(randImgPath)\n",
    "qY = np.asarray(loadedRandImg.quantization[0]).astype('uint8')\n",
    "qUV = np.asarray(loadedRandImg.quantization[1]).astype('uint8')\n",
    "qY = qY.astype(dtype)/255.\n",
    "qUV = qUV.astype(dtype)/255.\n",
    "import os\n",
    "os.remove(randImgPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fftSz1 = (480,320)\n",
    "fftSz2 = (320,480)\n",
    "smooth_jpeg1 = jrf.Smooth_JPEG(rho,alpha,noi,qY,qUV,lmbda,fftSz1,dtype=dtype)\n",
    "smooth_jpeg2 = jrf.Smooth_JPEG(rho,alpha,noi,qY,qUV,lmbda,fftSz2,dtype=dtype)\n",
    "Yoffset = tf.one_hot([[[0]]],64,tf.cast(32.,dtype = dtype),tf.cast(0.,dtype= dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataPath = 'data/original/simpleTest/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatype = 'train/'\n",
    "filelist = os.listdir(dataPath + datatype)\n",
    "ii = 0\n",
    "for filename in filelist:\n",
    "    if ii == img_ind:\n",
    "        break\n",
    "    ii += 1\n",
    "loadedPILImg = PIL.Image.open(dataPath + datatype + filename)\n",
    "loadedImg = np.asarray(loadedPILImg).astype(dtype)/255.\n",
    "loadedImgShape = loadedImg.shape\n",
    "# crop out a row and a column\n",
    "loadedImg = loadedImg[slice(0,loadedImgShape[0] - (loadedImgShape[0] % 8)),slice(0,loadedImgShape[1] - (loadedImgShape[1] % 8)),slice(None)]\n",
    "if loadedImgShape[0] - (loadedImgShape[0] % 8) == 480 and loadedImgShape[1] - (loadedImgShape[1] % 8) == 320:\n",
    "    # compressedImg = smooth_jpeg1.Wt(jrf.threeChannelQuantize(smooth_jpeg1.W(tf.reshape(loadedImg,(1,) + loadedImg.shape)),qY,qUV,Yoffset))\n",
    "    lowpass,compressedImg,raw = smooth_jpeg1(tf.reshape(loadedImg,(1,) + loadedImg.shape))\n",
    "elif loadedImgShape[0] - (loadedImgShape[0] % 8) == 320 and loadedImgShape[1] - (loadedImgShape[1] % 8) == 480:\n",
    "    #compressedImg = smooth_jpeg2.Wt(jrf.threeChannelQuantize(smooth_jpeg2.W(tf.reshape(loadedImg,(1,) + loadedImg.shape)),qY,qUV,Yoffset))\n",
    "    lowpass,compressedImg,raw = smooth_jpeg2(tf.reshape(loadedImg,(1,) + loadedImg.shape))\n",
    "else:\n",
    "    raise ValueError('Unexpected Shape!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd7ec5b8dd8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd7ec65f1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "np_img = np.asarray(loadedPILImg).astype('uint8')\n",
    "plt.imshow(np_img[120:168,140:188,:])\n",
    "#Yoffset = tf.one_hot([[[0]]],64,tf.cast(32.,tf.as_dtype('float64')),tf.cast(0.,tf.as_dtype('float64')))\n",
    "#print(np.amax(np_img))\n",
    "#print(np.amin(np_img))\n",
    "#np_img_float = np_img.astype('float64')/255.\n",
    "#tf_img_float = tf.expand_dims(np_img_float,axis=0)\n",
    "#yuv_img = jrf.RGB2YUV(dtype=tf.as_dtype('float64'))(tf_img_float)\n",
    "#rgb_img = jrf.YUV2RGB(dtype=tf.as_dtype('float64'))(smooth_jpeg2.Wt(smooth_jpeg2.W(yuv_img)))\n",
    "#np_img = np.asarray(255.*tf.squeeze(rgb_img,axis=0)).astype('uint8')\n",
    "#plt.imshow(np_img)\n",
    "#quantized_img = jrf.threeChannelQuantize(smooth_jpeg2.W(yuv_img),qY,qUV,Yoffset)\n",
    "#rgb_img = jrf.YUV2RGB(dtype=tf.as_dtype('float64'))(smooth_jpeg2.Wt(quantized_img))\n",
    "#np_img = np.asarray(255.*tf.squeeze(rgb_img,axis=0)).astype('uint8')\n",
    "#plt.imshow(np_img)\n",
    "#quantized_yuv_img = smooth_jpeg2.Wt(quantized_img)\n",
    "#plt.imshow(yuv2rgb(quantized_yuv_img))\n",
    "#quantized_img = jrf.threeChannelQuantize(smooth_jpeg2.W(tf.expand_dims(jrf.RGB2YUV()(np.asarray(loadedPILImg).astype('float64')),axis=0)),qY,qUV,Yoffset)\n",
    "#plt.imshow(np.asarray(jrf.YUV2RGB()(tf.squeeze(smooth_jpeg2.Wt(quantized_img),axis=0))).astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 480, 3)\n",
      "246\n",
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd7ec668d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ci = yuv2rgb(compressedImg)\n",
    "plt.imshow(ci[120:168,140:188,:])\n",
    "print(ci.shape)\n",
    "print(np.amax(ci))\n",
    "print(np.amin(ci))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd7900e57b8>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd7ec5f1da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lp = yuv2rgb(lowpass)\n",
    "plt.imshow(lp[120:168,140:188,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import jpeg_related_functions as jrf\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "qY = np.array([[16, 11, 10, 16, 24, 40, 51, 61],\n",
    "              [12, 12, 14, 19, 26, 58, 60, 55],\n",
    "              [14, 13, 16, 24, 40, 57, 69, 56],\n",
    "              [14, 17, 22, 29, 51, 87, 80, 62],\n",
    "              [18, 22, 37, 56, 68, 109, 103, 77],\n",
    "              [24, 35, 55, 64, 81, 104, 113, 92],\n",
    "              [49, 64, 78, 87, 103, 121, 120, 101],\n",
    "              [72, 92, 95, 98, 112, 100, 103, 99]])\n",
    "qY = qY.astype('float64')/255.\n",
    "qUV = qY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "lmbda = 4.\n",
    "rho = 0.1\n",
    "alpha = 1.\n",
    "noi = 10\n",
    "image = Image.open(\"20190728_matthewdruincom_SLE_0033.jpg\")\n",
    "s = np.asarray(image).astype('float64')/255.\n",
    "s = s[slice(0,1600),slice(0,2800),slice(None)]\n",
    "s = np.reshape(s,(1,) + s.shape)\n",
    "fftSz = s.shape[1:3]\n",
    "smooth_jpeg = jrf.Smooth_JPEG(rho,alpha,noi,qY,qUV,lmbda,fftSz,dtype=tf.float64)\n",
    "#y,u,By,negC = smooth_jpeg.init_vars(s)\n",
    "#outputs = smooth_jpeg(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs = smooth_jpeg(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "highpass,lowpass = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x,y,u = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2.039646333059423, shape=(), dtype=float64)\n",
      "tf.Tensor(2.1151680018556487, shape=(), dtype=float64)\n",
      "tf.Tensor(0.8840874549355658, shape=(), dtype=float64)\n",
      "tf.Tensor(0.8297288644681492, shape=(), dtype=float64)\n",
      "tf.Tensor(1.3342601848054017, shape=(), dtype=float64)\n",
      "tf.Tensor(1.3342601848058462, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(tf.math.reduce_max(x))\n",
    "print(tf.math.reduce_max(y))\n",
    "print(tf.math.reduce_min(x))\n",
    "print(tf.math.reduce_min(y))\n",
    "print(tf.math.reduce_mean(x))\n",
    "print(tf.math.reduce_mean(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_init,u_init,By_init,negC,itstats = smooth_jpeg.init_vars(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.1837382249200323, shape=(), dtype=float64)\n",
      "tf.Tensor(-0.21214950634511898, shape=(), dtype=float64)\n",
      "tf.Tensor(0.3588879588149992, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(tf.reduce_max(y_init))\n",
    "print(tf.reduce_min(y_init))\n",
    "print(tf.reduce_mean(y_init))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.1837382249200323, shape=(), dtype=float64)\n",
      "tf.Tensor(-0.21214950634511898, shape=(), dtype=float64)\n",
      "tf.Tensor(0.3588879588149992, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(tf.reduce_max(smooth_jpeg.Wt(negC)))\n",
    "print(tf.reduce_min(smooth_jpeg.Wt(negC)))\n",
    "print(tf.reduce_mean(smooth_jpeg.Wt(negC)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.1837382249200323, shape=(), dtype=float64)\n",
      "tf.Tensor(-0.21214950634511898, shape=(), dtype=float64)\n",
      "tf.Tensor(0.3588879588149992, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(tf.reduce_max(smooth_jpeg.Wt(By_init)))\n",
    "print(tf.reduce_min(smooth_jpeg.Wt(By_init)))\n",
    "print(tf.reduce_mean(smooth_jpeg.Wt(By_init)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x,Ax = smooth_jpeg.xstep(y_init,u_init,By_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.0390829950833103, shape=(), dtype=float64)\n",
      "tf.Tensor(-0.03794457125802076, shape=(), dtype=float64)\n",
      "tf.Tensor(0.3596462283896552, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(tf.reduce_max(x))\n",
    "print(tf.reduce_min(x))\n",
    "print(tf.reduce_mean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AxplusC = smooth_jpeg.relax(Ax,By_init,negC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.0, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(tf.reduce_max(AxplusC[0] + negC[0]))\n",
    "print(tf.reduce_min(AxplusC[0] + negC[0]))\n",
    "print(tf.reduce_max(AxplusC[1] + negC[1]))\n",
    "print(tf.reduce_min(AxplusC[1] + negC[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y,By = smooth_jpeg.ystep(x,u_init,AxplusC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.095376683391678, shape=(), dtype=float64)\n",
      "tf.Tensor(1.1340443007804173, shape=(), dtype=float64)\n",
      "tf.Tensor(-0.07691133243708641, shape=(), dtype=float64)\n",
      "tf.Tensor(-0.11176080134176089, shape=(), dtype=float64)\n",
      "tf.Tensor(0.3598486538373756, shape=(), dtype=float64)\n",
      "tf.Tensor(0.3601107598790794, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(tf.reduce_max(y))\n",
    "print(tf.reduce_max(smooth_jpeg.Wt(By)))\n",
    "print(tf.reduce_min(y))\n",
    "print(tf.reduce_min(smooth_jpeg.Wt(By)))\n",
    "print(tf.reduce_mean(y))\n",
    "print(tf.reduce_mean(smooth_jpeg.Wt(By)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u = smooth_jpeg.ustep(u_init,AxplusC,By)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x,Ax = smooth_jpeg.xstep(y,u,By)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AxplusC = smooth_jpeg.relax(Ax,By,negC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y,By = smooth_jpeg.ystep(x,u,AxplusC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u = smooth_jpeg.ustep(u,AxplusC,By)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x,Ax = smooth_jpeg.xstep(s,u_init,By_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1600, 2800, 3)\n",
      "(1, 1600, 2800, 3)\n",
      "tf.Tensor(1.0, shape=(), dtype=float64)\n",
      "tf.Tensor(1.0000000000006473, shape=(), dtype=float64)\n",
      "tf.Tensor(0.0, shape=(), dtype=float64)\n",
      "tf.Tensor(-4.956660487039716e-13, shape=(), dtype=float64)\n",
      "tf.Tensor(0.3588261461251168, shape=(), dtype=float64)\n",
      "tf.Tensor(0.3588261461249889, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "import transforms as transf\n",
    "fft = transf.fft2d_multichannel(s.shape[1:3])\n",
    "ifft = transf.ifft2d_multichannel(s.shape[1:3])\n",
    "s_still = ifft(fft(s))\n",
    "print(s.shape)\n",
    "print(s_still.shape)\n",
    "\n",
    "print(tf.reduce_max(s))\n",
    "print(tf.reduce_max(s_still))\n",
    "print(tf.reduce_min(s))\n",
    "print(tf.reduce_min(s_still))\n",
    "print(tf.reduce_mean(s))\n",
    "print(tf.reduce_mean(s_still))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_new = tf.where(x < 0,0.,x)\n",
    "x_new = tf.where(x_new > 1.0,1.0,x_new)\n",
    "smoothImage = Image.fromarray((255.*np.asarray(tf.reshape(x_new,x_new.shape[1:]))).astype('uint8'),'RGB')\n",
    "smoothImage.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_new = tf.where(highpass < 0.,0.,highpass)\n",
    "y_new = tf.where(y_new > 1.0,1.0,y_new)\n",
    "smoothImage = Image.fromarray((255.*np.asarray(tf.reshape(y_new,y_new.shape[1:]))).astype('uint8'),'RGB')\n",
    "smoothImage.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lowpass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.2570130949512816, shape=(), dtype=float64)\n",
      "tf.Tensor(0.2570130949512816, shape=(), dtype=float64)\n",
      "tf.Tensor(0.04323715026838358, shape=(), dtype=float64)\n",
      "tf.Tensor(0.04323715026838358, shape=(), dtype=float64)\n",
      "tf.Tensor(0.07887996586296282, shape=(), dtype=float64)\n",
      "tf.Tensor(0.07887996586296282, shape=(), dtype=float64)\n",
      "tf.Tensor(-0.03274309150125233, shape=(), dtype=float64)\n",
      "tf.Tensor(-0.03274309150125233, shape=(), dtype=float64)\n",
      "tf.Tensor(-0.033754955995817404, shape=(), dtype=float64)\n",
      "tf.Tensor(-0.033754955995817404, shape=(), dtype=float64)\n",
      "tf.Tensor(-0.05825989553795034, shape=(), dtype=float64)\n",
      "tf.Tensor(-0.05825989553795034, shape=(), dtype=float64)\n",
      "tf.Tensor(0.06513041623543925, shape=(), dtype=float64)\n",
      "tf.Tensor(0.06513041623543925, shape=(), dtype=float64)\n",
      "tf.Tensor(-0.0011787114132774982, shape=(), dtype=float64)\n",
      "tf.Tensor(-0.0011787114132774982, shape=(), dtype=float64)\n",
      "tf.Tensor(0.007870027512006482, shape=(), dtype=float64)\n",
      "tf.Tensor(0.007870027512006482, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "wtBy_yuv = tf.image.rgb_to_yuv(wtBy)\n",
    "wtBY_y,wtBY_u,wtBY_v = tf.split(wtBy_yuv,axis=3,num_or_size_splits=3)\n",
    "\n",
    "wtqwy = smooth_jpeg.Wt([smooth_jpeg.q*tf.math.round(smooth_jpeg.W(y)[channel]/smooth_jpeg.q) for channel in range(3)])\n",
    "wtqwy_yuv = tf.image.rgb_to_yuv(wtqwy)\n",
    "wtqwy_y,wtqwy_u,wtqwy_v = tf.split(wtqwy_yuv,axis=3,num_or_size_splits=3)\n",
    "\n",
    "print(tf.math.reduce_max(wtBY_y))\n",
    "print(tf.math.reduce_max(wtqwy_y))\n",
    "print(tf.math.reduce_max(wtBY_u))\n",
    "print(tf.math.reduce_max(wtqwy_u))\n",
    "print(tf.math.reduce_max(wtBY_v))\n",
    "print(tf.math.reduce_max(wtBY_v))\n",
    "print(tf.math.reduce_min(wtBY_y))\n",
    "print(tf.math.reduce_min(wtqwy_y))\n",
    "print(tf.math.reduce_min(wtBY_u))\n",
    "print(tf.math.reduce_min(wtqwy_u))\n",
    "print(tf.math.reduce_min(wtBY_v))\n",
    "print(tf.math.reduce_min(wtBY_v))\n",
    "print(tf.math.reduce_mean(wtBY_y))\n",
    "print(tf.math.reduce_mean(wtqwy_y))\n",
    "print(tf.math.reduce_mean(wtBY_u))\n",
    "print(tf.math.reduce_mean(wtqwy_u))\n",
    "print(tf.math.reduce_mean(wtBY_v))\n",
    "print(tf.math.reduce_mean(wtBY_v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lowpass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.cast(lowpass,tf.float32)\n",
    "x_small = x[slice(None),slice(0,256),slice(0,256),slice(None)]\n",
    "smoothImage = Image.fromarray(np.asarray(tf.reshape(x_small,x_small.shape[1:])),'RGB')\n",
    "smoothImage.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.92229486>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_max(x_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.8896151>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_min(x_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=1.0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_max(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_min(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_new,Ax_new = smooth_jpeg.xstep(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.9259259259265392>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_max(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=-4.566629576338341e-13>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_min(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lowpass = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lowpass = wtBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_new = tf.where(lowpass < 0,0.,lowpass)\n",
    "x_new = tf.where(x_new > 1.0,1.0,x_new)\n",
    "smoothImage = Image.fromarray((255.*np.asarray(tf.reshape(x_new,x_new.shape[1:]))).astype('uint8'),'RGB')\n",
    "smoothImage.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.025259007677445326, shape=(), dtype=float64)\n",
      "tf.Tensor(-0.004116784037421037, shape=(), dtype=float64)\n",
      "tf.Tensor(0.007235759263040731, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(tf.reduce_max(lowpass))\n",
    "print(tf.reduce_min(lowpass))\n",
    "print(tf.reduce_mean(lowpass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.5130693627046149>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_min(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.6106675396815834>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.7188945327525801>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_max(wtBy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.4095120582383085>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_min(wtBy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.5205163330596897>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(wtBy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 200, 350, 64])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smooth_jpeg.W(wtBy)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.613012462000272>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(smooth_jpeg.Wt([smooth_jpeg.q*tf.math.round(smooth_jpeg.W(y)[channel]/smooth_jpeg.q) for channel in range(3)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.09169928799980395>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_max(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.05429964236971775>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_min(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 1600, 2800, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smoothImage = Image.fromarray(np.asarray(tf.reshape(x_new,x_new.shape[1:]))*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "image = Image.open(\"20190728_matthewdruincom_SLE_0033.jpg\")\n",
    "#image = Image.open(\"20200202_matthewdruincom_SLW_0085.jpg\")\n",
    "#image.show()\n",
    "import numpy as np\n",
    "x_orig = np.asarray(image).astype('float64')\n",
    "\n",
    "x_batch = np.reshape(x_orig.astype('float64')/255.,(1,)+x_orig.shape)\n",
    "x_batch = x_batch[slice(None),slice(0,1600),slice(0,2800),slice(None)]\n",
    "x = (np.reshape(x_batch,x_batch.shape[1:])*255.).astype('uint8')\n",
    "x_orig = Image.fromarray(x)\n",
    "x_cmprss = tf.image.adjust_jpeg_quality(x,25)\n",
    "image_cmprss = Image.fromarray(np.asarray(x_cmprss),'RGB')\n",
    "image_cmprss.show()\n",
    "x_cmprss_batch = np.reshape(np.asarray(x_cmprss).astype('float64')/255.,(1,)+x_cmprss.shape)\n",
    "#x_cmprss_apprx = jrf.Linear_JPEG_Compression_Approx(x_cmprss_batch)(x_batch)\n",
    "#image_cmprss_apprx = Image.fromarray(np.asarray(x_cmprss_apprx*255).astype('uint8'),'RGB')\n",
    "#image_cmprss_apprx.show\n",
    "\n",
    "#y = jpeg_coef2rgb(rgb2jpeg_coef(x))\n",
    "#z = jpeg_coef2rgb(rgb2jpeg_coef(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1600, 2800, 3)\n",
      "(1, 1600, 2800, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_batch.shape)\n",
    "print(x_cmprss_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer rg_b2jpeg__coef_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer linear_jpeg__compression__approx is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_cmprss_apprx = jrf.Linear_JPEG_Compression_Approx(x_cmprss_batch,epsilon=1e-3)(x_batch)\n",
    "#print(tf.math.reduce_min(tf.where(jrf.Linear_JPEG_Compression_Approx(x_cmprss_batch).masky,1.0,0.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_cmprss_apprx = Image.fromarray(np.asarray(tf.reshape(x_cmprss_apprx,x_cmprss_apprx.shape[1:])*255).astype('uint8'),'RGB')\n",
    "image_cmprss_apprx.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.0698118, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.math.reduce_max(x_cmprss_apprx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.reduce_min(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.21713108, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.math.reduce_max(tf.math.abs(x - y)))\n",
    "print(tf.math.reduce_max(tf.math.abs(z - y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([5, 128, 128, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.22571766>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.4955484>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.one_hot(indices=[[[0]]],depth=64,on_value=2.,dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 1, 1, 64])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=2.0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
