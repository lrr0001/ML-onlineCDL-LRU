{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class OuterProd(tf.keras.layers.Layer):\n",
    "    def __init__(self,*args,**kwargs):\n",
    "        super().__init__(self,*args,**kwargs)\n",
    "        \n",
    "    def call(self,input1,input2):\n",
    "        factor1 = tf.reshape(input1,shape=input1.shape + (1,))\n",
    "        factor2 = tf.math.conj(tf.reshape(input2,shape=input2.shape[:-1] + (1,) + input2.shape[-1]))\n",
    "        return factor1*factor2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5725 - val_loss: 0.6199\n",
      "Epoch 2/16\n",
      "100/100 [==============================] - 0s 880us/step - loss: 0.4739 - val_loss: 0.5757\n",
      "Epoch 3/16\n",
      "100/100 [==============================] - 0s 928us/step - loss: 0.3189 - val_loss: 0.1571\n",
      "Epoch 4/16\n",
      "100/100 [==============================] - 0s 912us/step - loss: 0.0318 - val_loss: 0.0021\n",
      "Epoch 5/16\n",
      "100/100 [==============================] - 0s 863us/step - loss: 4.5103e-04 - val_loss: 3.3355e-05\n",
      "Epoch 6/16\n",
      "100/100 [==============================] - 0s 767us/step - loss: 8.3255e-06 - val_loss: 6.5757e-07\n",
      "Epoch 7/16\n",
      "100/100 [==============================] - 0s 873us/step - loss: 1.6540e-07 - val_loss: 1.2799e-08\n",
      "Epoch 8/16\n",
      "100/100 [==============================] - 0s 894us/step - loss: 3.2806e-09 - val_loss: 2.5367e-10\n",
      "Epoch 9/16\n",
      "100/100 [==============================] - 0s 826us/step - loss: 6.5189e-11 - val_loss: 5.1506e-12\n",
      "Epoch 10/16\n",
      "100/100 [==============================] - 0s 874us/step - loss: 1.3211e-12 - val_loss: 1.4338e-13\n",
      "Epoch 11/16\n",
      "100/100 [==============================] - 0s 833us/step - loss: 6.0850e-14 - val_loss: 4.3237e-14\n",
      "Epoch 12/16\n",
      "100/100 [==============================] - 0s 930us/step - loss: 3.3969e-14 - val_loss: 3.9746e-14\n",
      "Epoch 13/16\n",
      "100/100 [==============================] - 0s 846us/step - loss: 3.2902e-14 - val_loss: 3.9390e-14\n",
      "Epoch 14/16\n",
      "100/100 [==============================] - 0s 846us/step - loss: 3.2768e-14 - val_loss: 3.9388e-14\n",
      "Epoch 15/16\n",
      "100/100 [==============================] - 0s 793us/step - loss: 3.2682e-14 - val_loss: 3.9390e-14\n",
      "Epoch 16/16\n",
      "100/100 [==============================] - 0s 734us/step - loss: 3.2820e-14 - val_loss: 3.9367e-14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'matrix_and_vector/Variable:0' shape=(1, 2) dtype=float32, numpy=array([[1.5817825e-08, 9.9999988e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MatrixAndVector(tf.keras.layers.Layer):\n",
    "    def __init__(self,v=None,*args,**kwargs):\n",
    "        super().__init__(*args,**kwargs)\n",
    "        self.v = v\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        if self.v is not None:\n",
    "            self.V = tf.Variable(initial_value=self.v,trainable=True,dtype=self.dtype)\n",
    "        else:\n",
    "            self.V = tf.Variable(initial_value=tf.random.normal(shape=(1,) + input_shape[1:]),trainable=True,dtype=self.dtype)\n",
    "        self.setupA(input_shape,self.V)\n",
    "        \n",
    "    def setupA(self,input_shape,V):\n",
    "        idmat = tf.eye(num_rows=input_shape[-1],batch_shape=(1,) + input_shape[1:-1],dtype=self.dtype)\n",
    "        self.L = tf.Variable(initial_value = tf.linalg.cholesky(idmat + OuterProd(dtype=self.dtype)(self.V,self.V)), trainable = False,dtype=self.dtype)        \n",
    "    def applyA(self,x):\n",
    "        return tf.linalg.matvec(self.L,tf.linalg.matvec(self.L,x,adjoint_a=True))\n",
    "    def call(self, inputs):\n",
    "        Ax = self.applyA(inputs)\n",
    "        vvhx = tf.reduce_sum(inputs*tf.math.conj(self.V),axis=-1,keepdims=True)*self.V\n",
    "        return  Ax + vvhx\n",
    "\n",
    "\n",
    "v_init = np.zeros(shape=(1,2))\n",
    "v_init[slice(None),0] = 1\n",
    "                             \n",
    "x = tf.keras.layers.Input((2,))\n",
    "ApVVh= MatrixAndVector(v_init)\n",
    "y = ApVVh(x)\n",
    "model = tf.keras.Model(x,y)\n",
    "model.compile(optimizer = tf.keras.optimizers.SGD(),loss=tf.keras.losses.MeanSquaredError())\n",
    "\n",
    "x_train=np.random.randn(1000,2)\n",
    "y_train = 2*x_train\n",
    "x_val=np.random.randn(100,2)\n",
    "y_val = 2*x_val\n",
    "model.fit(x=x_train,y=y_train,batch_size=10,epochs=16,validation_data=(x_val,y_val))\n",
    "ApVVh.V\n",
    "                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'float32'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ApVVh.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PostProcess:\n",
    "    update = {}\n",
    "class CustomTrainModel(tf.keras.Model):\n",
    "    def train_step(self,data):\n",
    "        myoutputs = tf.keras.Model.train_step(self,data)\n",
    "        for tv in self.trainable_variables:\n",
    "            if tv.name in PostProcess.update:\n",
    "                PostProcess.update[tv.name]()\n",
    "        return myoutputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eigvecReversal(U,V):\n",
    "    vtv = tf.reduce_sum(V*V,axis=-1,keepdims=True)\n",
    "    utu = tf.reduce_sum(U*U,axis=-1,keepdims=True)\n",
    "    utv = tf.reduce_sum(U*V,axis=-1,keepdims=True)\n",
    "    utvs = tf.reshape(utv,utv.shape[:-1])\n",
    "    rootRadicand = tf.math.sqrt(vtv*utu)\n",
    "    rootRadicands = tf.reshape(rootRadicand,rootRadicand.shape[:-1])\n",
    "        \n",
    "    valPlus = utvs + rootRadicands\n",
    "    valMinus = utvs - rootRadicands\n",
    "    vecPlus = vtv*U + rootRadicand*V\n",
    "    vecMinus = vtv*U - rootRadicand*V\n",
    "    #vecPlus = tf.where(tf.abs(rootRadicand) > 1e-5,vecPlus,U)\n",
    "    #vecMinus = tf.where(tf.abs(rootRadicand) > 1e-5,vecMinus,-tf.math.divide_no_nan(utv,utu)*U + V)\n",
    "    #tf.debugging.Assert(condition=tf.abs(rootRadicands) > 1e-5,data=rootRadicands)\n",
    "        \n",
    "    vecPlus = tf.math.l2_normalize(vecPlus,epsilon=1e-5)\n",
    "    vecMinus = tf.math.l2_normalize(vecMinus,epsilon=1e-5)\n",
    "    return ((valPlus,valMinus),(vecPlus,vecMinus))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "U = tf.random.normal((1,2))\n",
    "V = tf.random.normal((1,2))\n",
    "eigvals,eigvecs = eigvecReversal(U,V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-1.8185118   0.5211488 ]\n",
      "  [ 0.5211488   0.77038383]]], shape=(1, 2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[-1.8185118  0.5211488]\n",
      "  [ 0.5211488  0.7703838]]], shape=(1, 2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "A = OuterProd()(U,V) + OuterProd()(V,U)\n",
    "print(A)\n",
    "A_again = eigvals[0]*OuterProd()(eigvecs[0],eigvecs[0]) + eigvals[1]*OuterProd()(eigvecs[1],eigvecs[1])\n",
    "print(A_again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5707 - val_loss: 0.4725\n",
      "Epoch 2/16\n",
      "100/100 [==============================] - 0s 870us/step - loss: 0.4767 - val_loss: 0.4467\n",
      "Epoch 3/16\n",
      "100/100 [==============================] - 0s 914us/step - loss: 0.3792 - val_loss: 0.2067\n",
      "Epoch 4/16\n",
      "100/100 [==============================] - 0s 907us/step - loss: 0.0652 - val_loss: 0.0039\n",
      "Epoch 5/16\n",
      "100/100 [==============================] - 0s 852us/step - loss: 9.5699e-04 - val_loss: 6.3413e-05\n",
      "Epoch 6/16\n",
      "100/100 [==============================] - 0s 808us/step - loss: 1.7138e-05 - val_loss: 1.2715e-06\n",
      "Epoch 7/16\n",
      "100/100 [==============================] - 0s 846us/step - loss: 3.4603e-07 - val_loss: 2.5757e-08\n",
      "Epoch 8/16\n",
      "100/100 [==============================] - 0s 808us/step - loss: 7.0086e-09 - val_loss: 5.2393e-10\n",
      "Epoch 9/16\n",
      "100/100 [==============================] - 0s 872us/step - loss: 1.4275e-10 - val_loss: 1.0633e-11\n",
      "Epoch 10/16\n",
      "100/100 [==============================] - 0s 814us/step - loss: 2.9106e-12 - val_loss: 2.3571e-13\n",
      "Epoch 11/16\n",
      "100/100 [==============================] - 0s 823us/step - loss: 7.5229e-14 - val_loss: 2.3267e-14\n",
      "Epoch 12/16\n",
      "100/100 [==============================] - 0s 887us/step - loss: 1.5916e-14 - val_loss: 1.5565e-14\n",
      "Epoch 13/16\n",
      "100/100 [==============================] - 0s 855us/step - loss: 1.4542e-14 - val_loss: 1.5192e-14\n",
      "Epoch 14/16\n",
      "100/100 [==============================] - 0s 828us/step - loss: 1.4370e-14 - val_loss: 1.5192e-14\n",
      "Epoch 15/16\n",
      "100/100 [==============================] - 0s 808us/step - loss: 1.4398e-14 - val_loss: 1.5195e-14\n",
      "Epoch 16/16\n",
      "100/100 [==============================] - 0s 844us/step - loss: 1.4348e-14 - val_loss: 1.5194e-14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'new_matrix_and_vector/Variable:0' shape=(1, 2) dtype=float32, numpy=array([[ 1.1247319e-08, -9.9999994e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "class NewMatrixAndVector(MatrixAndVector):\n",
    "    def build(self,input_shape):\n",
    "        super().build(input_shape)\n",
    "    def setupA(self,input_shape,V):\n",
    "        idmat = tf.eye(num_rows=input_shape[-1],batch_shape=(1,) + input_shape[1:-1],dtype=self.dtype)\n",
    "        self.A = tf.Variable(initial_value = idmat + OuterProd(dtype=self.dtype)(self.V,self.V), trainable = False)\n",
    "    def applyA(self,x):\n",
    "        return tf.linalg.matvec(self.A,x)\n",
    "\n",
    "v_init = np.zeros(shape=(1,2))\n",
    "v_init[slice(None),0] = 1\n",
    "\n",
    "ApVVh= NewMatrixAndVector(v_init)\n",
    "                             \n",
    "x = tf.keras.layers.Input((2,))\n",
    "y = ApVVh(x)\n",
    "model = CustomTrainModel(x,y)\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(),loss=tf.keras.losses.MeanSquaredError(),run_eagerly=False)\n",
    "\n",
    "x_train=np.random.randn(1000,2)\n",
    "y_train = 2*x_train\n",
    "x_val=np.random.randn(100,2)\n",
    "y_val = 2*x_val\n",
    "model.fit(x=x_train,y=y_train,batch_size=10,epochs=16,validation_data=(x_val,y_val))\n",
    "ApVVh.V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.3161 - val_loss: 0.2286\n",
      "Epoch 2/16\n",
      "100/100 [==============================] - 0s 893us/step - loss: 0.1446 - val_loss: 0.1330\n",
      "Epoch 3/16\n",
      "100/100 [==============================] - 0s 900us/step - loss: 0.0913 - val_loss: 0.0807\n",
      "Epoch 4/16\n",
      "100/100 [==============================] - 0s 903us/step - loss: 0.0596 - val_loss: 0.0569\n",
      "Epoch 5/16\n",
      "100/100 [==============================] - 0s 917us/step - loss: 0.0433 - val_loss: 0.0391\n",
      "Epoch 6/16\n",
      "100/100 [==============================] - 0s 876us/step - loss: 0.0312 - val_loss: 0.0319\n",
      "Epoch 7/16\n",
      "100/100 [==============================] - 0s 906us/step - loss: 0.0259 - val_loss: 0.0264\n",
      "Epoch 8/16\n",
      "100/100 [==============================] - 0s 889us/step - loss: 0.0213 - val_loss: 0.0217\n",
      "Epoch 9/16\n",
      "100/100 [==============================] - 0s 935us/step - loss: 0.0179 - val_loss: 0.0181\n",
      "Epoch 10/16\n",
      "100/100 [==============================] - 0s 879us/step - loss: 0.0153 - val_loss: 0.0156\n",
      "Epoch 11/16\n",
      "100/100 [==============================] - 0s 900us/step - loss: 0.0131 - val_loss: 0.0137\n",
      "Epoch 12/16\n",
      "100/100 [==============================] - 0s 907us/step - loss: 0.0116 - val_loss: 0.0125\n",
      "Epoch 13/16\n",
      "100/100 [==============================] - 0s 887us/step - loss: 0.0107 - val_loss: 0.0113\n",
      "Epoch 14/16\n",
      "100/100 [==============================] - 0s 889us/step - loss: 0.0095 - val_loss: 0.0108\n",
      "Epoch 15/16\n",
      "100/100 [==============================] - 0s 945us/step - loss: 0.0086 - val_loss: 0.0092\n",
      "Epoch 16/16\n",
      "100/100 [==============================] - 0s 893us/step - loss: 0.0079 - val_loss: 0.0084\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'new_matrix_and_vector_4/Variable:0' shape=(1, 2) dtype=float32, numpy=array([[1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "class NewMatrixAndVector(MatrixAndVector,PostProcess):\n",
    "    def build(self,input_shape):\n",
    "        super().build(input_shape)\n",
    "        self.Vfixed = tf.Variable(initial_value=tf.identity(self.V),trainable=False,dtype=self.dtype)\n",
    "        PostProcess.update[self.V.name] = self.post_update\n",
    "    def setupA(self,input_shape,V):\n",
    "        idmat = tf.eye(num_rows=input_shape[-1],batch_shape=(1,) + input_shape[1:-1],dtype=self.dtype)\n",
    "        self.A = tf.Variable(initial_value = idmat + OuterProd(dtype=self.dtype)(self.V,self.V), trainable = False)\n",
    "    def applyA(self,x):\n",
    "        return tf.linalg.matvec(self.A,x)\n",
    "    def updateA(self,u_vec,mult):\n",
    "        return self.A.assign(self.A + mult*OuterProd(dtype=self.dtype)(u_vec,u_vec))\n",
    "    def post_update(self):\n",
    "        U = self.V - self.Vfixed\n",
    "        with tf.control_dependencies([U]):\n",
    "            self.V.assign(self.Vfixed)\n",
    "        newA = self.updateA(U,1.0)\n",
    "        eigvals, eigvecs = eigvecReversal(U,self.Vfixed)\n",
    "        for ii in range(2):\n",
    "            with tf.control_dependencies([newA]):\n",
    "                newA = self.updateA(eigvecs[ii],eigvals[ii])\n",
    "\n",
    "v_init = np.zeros(shape=(1,2))\n",
    "v_init[slice(None),0] = 1\n",
    "\n",
    "ApVVh= NewMatrixAndVector(v_init)\n",
    "                             \n",
    "x = tf.keras.layers.Input((2,))\n",
    "y = ApVVh(x)\n",
    "model = CustomTrainModel(x,y)\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(0.2),loss=tf.keras.losses.MeanSquaredError(),run_eagerly=False)\n",
    "\n",
    "x_train=np.random.randn(1000,2)\n",
    "y_train = 2*x_train\n",
    "x_val=np.random.randn(100,2)\n",
    "y_val = 2*x_val\n",
    "model.fit(x=x_train,y=y_train,batch_size=10,epochs=16,validation_data=(x_val,y_val))\n",
    "ApVVh.V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NewMatrixAndVector' object has no attribute 'A'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-8f83398caf5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mApVVh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NewMatrixAndVector' object has no attribute 'A'"
     ]
    }
   ],
   "source": [
    "print(ApVVh.A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.3534 - val_loss: 0.1727\n",
      "Epoch 2/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1708 - val_loss: 0.0833\n",
      "Epoch 3/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0863 - val_loss: 0.0519\n",
      "Epoch 4/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0542 - val_loss: 0.0309\n",
      "Epoch 5/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0351 - val_loss: 0.0223\n",
      "Epoch 6/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0255 - val_loss: 0.0164\n",
      "Epoch 7/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0125\n",
      "Epoch 8/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0105\n",
      "Epoch 9/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0087\n",
      "Epoch 10/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0079\n",
      "Epoch 11/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0071\n",
      "Epoch 12/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0063\n",
      "Epoch 13/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0058\n",
      "Epoch 14/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0050\n",
      "Epoch 15/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0047\n",
      "Epoch 16/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'new_matrix_and_vector_49/Variable:0' shape=(1, 2) dtype=float32, numpy=array([[1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "class NewMatrixAndVector(MatrixAndVector,PostProcess):\n",
    "    def build(self,input_shape):\n",
    "        super().build(input_shape)\n",
    "        self.Vfixed = tf.Variable(initial_value=tf.identity(self.V),trainable=False,dtype=self.dtype)\n",
    "        PostProcess.update[self.V.name] = self.post_update\n",
    "    def updateA(self,u_vec,mult):\n",
    "        return self.L.assign(tfp.math.cholesky_update(self.L,update_vector=u_vec,multiplier=mult))\n",
    "    def post_update(self):\n",
    "        U = self.V - self.Vfixed\n",
    "        #print(U)\n",
    "        with tf.control_dependencies([U]):\n",
    "            self.V.assign(self.Vfixed)\n",
    "        newA = self.updateA(U,1.0)\n",
    "        #print(tf.matmul(newA,newA,adjoint_b=True))\n",
    "        eigvals, eigvecs = eigvecReversal(U,self.Vfixed)\n",
    "        for ii in range(2):\n",
    "            with tf.control_dependencies([newA]):\n",
    "                newA = self.updateA(eigvecs[ii],eigvals[ii])\n",
    "\n",
    "v_init = np.zeros((1,2))\n",
    "b = np.zeros(shape=(1,2))\n",
    "b[slice(None),0] = 1\n",
    "v_init[slice(None),0] = 1\n",
    "\n",
    "ApVVh= NewMatrixAndVector(v_init)\n",
    "                             \n",
    "x = tf.keras.layers.Input((2,))\n",
    "y = ApVVh(x)\n",
    "model = CustomTrainModel(x,y)\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(0.2),loss=tf.keras.losses.MeanSquaredError(),run_eagerly=False)\n",
    "\n",
    "x_train=np.random.randn(1000,2)\n",
    "y_train = 2*x_train\n",
    "x_val=np.random.randn(100,2)\n",
    "y_val = 2*x_val\n",
    "model.fit(x=x_train,y=y_train,batch_size=10,epochs=16,validation_data=(x_val,y_val))\n",
    "ApVVh.V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[1.00850006+0.j         0.0021042 +0.00019345j]\n",
      "  [0.0021042 -0.00019345j 1.34594523+0.j        ]]], shape=(1, 2, 2), dtype=complex128)\n"
     ]
    }
   ],
   "source": [
    "print(tf.linalg.matmul(ApVVh.L,ApVVh.L,adjoint_b=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def complexNum(x):\n",
    "    return tf.complex(x,tf.cast(0.0,dtype = x.dtype))\n",
    "\n",
    "def eigvecReversal(U,V):\n",
    "    vhv = tf.reduce_sum(tf.math.conj(V)*V,axis=-1,keepdims=True)\n",
    "    uhu = tf.reduce_sum(tf.math.conj(U)*U,axis=-1,keepdims=True)\n",
    "    uhv = tf.reduce_sum(tf.math.conj(U)*V,axis=-1,keepdims=True)\n",
    "    rootRadicand = tf.math.sqrt(vhv*uhu - complexNum(tf.math.imag(uhv)**2))\n",
    "        \n",
    "    valPlus = complexNum(tf.math.real(uhv)) + rootRadicand\n",
    "    valMinus = complexNum(tf.math.real(uhv)) - rootRadicand\n",
    "    vecPlus = vhv*U + (1j*complexNum(tf.math.imag(uhv)) + rootRadicand)*V\n",
    "    vecMinus = vhv*U + (1j*complexNum(tf.math.imag(uhv))  - rootRadicand)*V\n",
    "    vecPlus = tf.where(tf.abs(rootRadicand) > 1e-5,vecPlus,U)\n",
    "    vecMinus = tf.where(tf.abs(rootRadicand) > 1e-5,vecMinus,-tf.math.divide_no_nan(uhv,uhu)*U + V)\n",
    "    #tf.debugging.Assert(condition=tf.abs(rootRadicands) > 1e-5,data=rootRadicands)\n",
    "        \n",
    "    vecPlus = tf.math.l2_normalize(vecPlus,epsilon=1e-5)\n",
    "    vecMinus = tf.math.l2_normalize(vecMinus,epsilon=1e-5)\n",
    "    valPlus = tf.reshape(valPlus,valPlus.shape[:-1])\n",
    "    valMinus = tf.reshape(valMinus,valMinus.shape[:-1])\n",
    "    return ((valPlus,valMinus),(vecPlus,vecMinus))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "U = tf.complex(tf.random.normal((1,2)),tf.random.normal((1,2)))\n",
    "V = tf.complex(tf.random.normal((1,2)),tf.random.normal((1,2)))\n",
    "eigvals,eigvecs = eigvecReversal(U,V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 1.3619424 +0.j         -0.34927106+0.65208745j]\n",
      "  [-0.34927106-0.65208745j -0.63275087+0.j        ]]], shape=(1, 2, 2), dtype=complex64)\n",
      "tf.Tensor(\n",
      "[[[ 1.3619424 +0.j        -0.34927112+0.6520874j]\n",
      "  [-0.34927112-0.6520874j -0.632751  +0.j       ]]], shape=(1, 2, 2), dtype=complex64)\n"
     ]
    }
   ],
   "source": [
    "A = OuterProd()(U,V) + OuterProd()(V,U)\n",
    "print(A)\n",
    "A_again = eigvals[0]*OuterProd()(eigvecs[0],eigvecs[0]) + eigvals[1]*OuterProd()(eigvecs[1],eigvecs[1])\n",
    "print(A_again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def complexNum(x):\n",
    "    return tf.complex(x,tf.cast(0.0,dtype = x.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.0025 - val_loss: 0.8515\n",
      "Epoch 2/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9445 - val_loss: 1.0328\n",
      "Epoch 3/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9699 - val_loss: 0.9899\n",
      "Epoch 4/16\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.1846 - val_loss: 1.2318\n",
      "Epoch 5/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.0773 - val_loss: 0.8459\n",
      "Epoch 6/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9425 - val_loss: 0.9193\n",
      "Epoch 7/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8931 - val_loss: 0.8199\n",
      "Epoch 8/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.7126 - val_loss: 0.6390\n",
      "Epoch 9/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6638 - val_loss: 0.6238\n",
      "Epoch 10/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5381 - val_loss: 0.4901\n",
      "Epoch 11/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5518 - val_loss: 0.5220\n",
      "Epoch 12/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5503 - val_loss: 0.5505\n",
      "Epoch 13/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5390 - val_loss: 0.5366\n",
      "Epoch 14/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4986 - val_loss: 0.4721\n",
      "Epoch 15/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4929 - val_loss: 0.4676\n",
      "Epoch 16/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.4771 - val_loss: 0.4387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'new_matrix_and_vector_1/Variable:0' shape=(1, 2) dtype=complex128, numpy=array([[1.+0.j, 0.+0.j]])>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow_probability as tfp\n",
    "class NewMatrixAndVector(MatrixAndVector,PostProcess):\n",
    "    def build(self,input_shape):\n",
    "        super().build(input_shape)\n",
    "        self.Vfixed = tf.Variable(initial_value=tf.identity(self.V),trainable=False,dtype=self.dtype)\n",
    "        PostProcess.update[self.V.name] = self.post_update\n",
    "    def updateA(self,u_vec,mult):\n",
    "        return self.L.assign(tfp.math.cholesky_update(self.L,update_vector=u_vec,multiplier=mult))\n",
    "    def post_update(self):\n",
    "        U = self.V - self.Vfixed\n",
    "        with tf.control_dependencies([U]):\n",
    "            self.V.assign(self.Vfixed)\n",
    "        newA = self.updateA(U,1.0)\n",
    "        eigvals, eigvecs = eigvecReversal(U,self.Vfixed)\n",
    "        for ii in range(2):\n",
    "            with tf.control_dependencies([newA]):\n",
    "                newA = self.updateA(eigvecs[ii],eigvals[ii])\n",
    "\n",
    "v_a = np.zeros((1,2))\n",
    "v_a[slice(None),0] = 1\n",
    "v_b = np.zeros(shape=(1,2))\n",
    "#v_b[slice(None),1] = 0.5\n",
    "v_init = tf.complex(v_a,v_b)\n",
    "\n",
    "ApVVh= NewMatrixAndVector(v_init,dtype=tf.complex128)\n",
    "\n",
    "                             \n",
    "x = tf.keras.layers.Input((2,),dtype = tf.complex128)\n",
    "y = ApVVh(x)\n",
    "model = CustomTrainModel(x,y)\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(.1),loss=tf.keras.losses.MeanSquaredError(),run_eagerly=False)\n",
    "\n",
    "x_train=np.random.randn(1000,2) + 1j*np.random.randn(1000,2)\n",
    "y_train = 2*x_train\n",
    "x_val=np.random.randn(100,2) + 1j*np.random.randn(100,2)\n",
    "y_val = 2*x_val\n",
    "model.fit(x=x_train,y=y_train,batch_size=10,epochs=16,validation_data=(x_val,y_val))\n",
    "ApVVh.V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
