{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class OuterProd(tf.keras.layers.Layer):\n",
    "    def __init__(self,*args,**kwargs):\n",
    "        super().__init__(self,*args,**kwargs)\n",
    "        \n",
    "    def call(self,input1,input2):\n",
    "        factor1 = tf.reshape(input1,shape=input1.shape + (1,))\n",
    "        factor2 = tf.math.conj(tf.reshape(input2,shape=input2.shape[:-1] + (1,) + input2.shape[-1]))\n",
    "        return factor1*factor2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5915 - val_loss: 0.4893\n",
      "Epoch 2/16\n",
      "100/100 [==============================] - 0s 838us/step - loss: 0.4990 - val_loss: 0.4748\n",
      "Epoch 3/16\n",
      "100/100 [==============================] - 0s 834us/step - loss: 0.4641 - val_loss: 0.3753\n",
      "Epoch 4/16\n",
      "100/100 [==============================] - 0s 860us/step - loss: 0.1831 - val_loss: 0.0185\n",
      "Epoch 5/16\n",
      "100/100 [==============================] - 0s 838us/step - loss: 0.0041 - val_loss: 1.6049e-04\n",
      "Epoch 6/16\n",
      "100/100 [==============================] - 0s 817us/step - loss: 4.3296e-05 - val_loss: 2.5122e-06\n",
      "Epoch 7/16\n",
      "100/100 [==============================] - 0s 866us/step - loss: 6.8557e-07 - val_loss: 4.0607e-08\n",
      "Epoch 8/16\n",
      "100/100 [==============================] - 0s 844us/step - loss: 1.1087e-08 - val_loss: 6.6043e-10\n",
      "Epoch 9/16\n",
      "100/100 [==============================] - 0s 848us/step - loss: 1.8002e-10 - val_loss: 1.0848e-11\n",
      "Epoch 10/16\n",
      "100/100 [==============================] - 0s 804us/step - loss: 2.9694e-12 - val_loss: 2.0944e-13\n",
      "Epoch 11/16\n",
      "100/100 [==============================] - 0s 859us/step - loss: 8.2342e-14 - val_loss: 3.2886e-14\n",
      "Epoch 12/16\n",
      "100/100 [==============================] - 0s 834us/step - loss: 3.4438e-14 - val_loss: 3.0333e-14\n",
      "Epoch 13/16\n",
      "100/100 [==============================] - 0s 891us/step - loss: 3.2868e-14 - val_loss: 3.0307e-14\n",
      "Epoch 14/16\n",
      "100/100 [==============================] - 0s 907us/step - loss: 3.2832e-14 - val_loss: 3.0310e-14\n",
      "Epoch 15/16\n",
      "100/100 [==============================] - 0s 916us/step - loss: 3.2838e-14 - val_loss: 3.0283e-14\n",
      "Epoch 16/16\n",
      "100/100 [==============================] - 0s 851us/step - loss: 3.2834e-14 - val_loss: 3.0283e-14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'matrix_and_vector/Variable:0' shape=(1, 2) dtype=float32, numpy=array([[1.0283290e-09, 1.0000001e+00]], dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MatrixAndVector(tf.keras.layers.Layer):\n",
    "    def __init__(self,v=None,*args,**kwargs):\n",
    "        super().__init__(*args,**kwargs)\n",
    "        self.v = v\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        if self.v is not None:\n",
    "            self.V = tf.Variable(initial_value=self.v,trainable=True,dtype=self.dtype)\n",
    "        else:\n",
    "            self.V = tf.Variable(initial_value=tf.random.normal(shape=(1,) + input_shape[1:]),trainable=True,dtype=self.dtype)\n",
    "        self.setupA(input_shape,self.V)\n",
    "        \n",
    "    def setupA(self,input_shape,V):\n",
    "        idmat = tf.eye(num_rows=input_shape[-1],batch_shape=(1,) + input_shape[1:-1],dtype=self.dtype)\n",
    "        self.L = tf.Variable(initial_value = tf.linalg.cholesky(idmat + OuterProd(dtype=self.dtype)(self.V,self.V)), trainable = False,dtype=self.dtype)        \n",
    "    def applyA(self,x):\n",
    "        return tf.linalg.matvec(self.L,tf.linalg.matvec(self.L,x,adjoint_a=True))\n",
    "    def call(self, inputs):\n",
    "        Ax = self.applyA(inputs)\n",
    "        vvhx = tf.reduce_sum(inputs*tf.math.conj(self.V),axis=-1,keepdims=True)*self.V\n",
    "        return  Ax + vvhx\n",
    "\n",
    "\n",
    "v_init = np.zeros(shape=(1,2))\n",
    "v_init[slice(None),0] = 1\n",
    "                             \n",
    "x = tf.keras.layers.Input((2,))\n",
    "ApVVh= MatrixAndVector(v_init)\n",
    "y = ApVVh(x)\n",
    "model = tf.keras.Model(x,y)\n",
    "model.compile(optimizer = tf.keras.optimizers.SGD(),loss=tf.keras.losses.MeanSquaredError())\n",
    "\n",
    "x_train=np.random.randn(1000,2)\n",
    "y_train = 2*x_train\n",
    "x_val=np.random.randn(100,2)\n",
    "y_val = 2*x_val\n",
    "model.fit(x=x_train,y=y_train,batch_size=10,epochs=16,validation_data=(x_val,y_val))\n",
    "ApVVh.V\n",
    "                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'float32'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ApVVh.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PostProcess:\n",
    "    update = {}\n",
    "class CustomTrainModel(tf.keras.Model):\n",
    "    def train_step(self,data):\n",
    "        myoutputs = tf.keras.Model.train_step(self,data)\n",
    "        for tv in self.trainable_variables:\n",
    "            if tv.name in PostProcess.update:\n",
    "                PostProcess.update[tv.name]()\n",
    "        return myoutputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eigvecReversal(U,V):\n",
    "    vtv = tf.reduce_sum(V*V,axis=-1,keepdims=True)\n",
    "    utu = tf.reduce_sum(U*U,axis=-1,keepdims=True)\n",
    "    utv = tf.reduce_sum(U*V,axis=-1,keepdims=True)\n",
    "    utvs = tf.reshape(utv,utv.shape[:-1])\n",
    "    rootRadicand = tf.math.sqrt(vtv*utu)\n",
    "    rootRadicands = tf.reshape(rootRadicand,rootRadicand.shape[:-1])\n",
    "        \n",
    "    valPlus = utvs + rootRadicands\n",
    "    valMinus = utvs - rootRadicands\n",
    "    vecPlus = vtv*U + rootRadicand*V\n",
    "    vecMinus = vtv*U - rootRadicand*V\n",
    "    #vecPlus = tf.where(tf.abs(rootRadicand) > 1e-5,vecPlus,U)\n",
    "    #vecMinus = tf.where(tf.abs(rootRadicand) > 1e-5,vecMinus,-tf.math.divide_no_nan(utv,utu)*U + V)\n",
    "    #tf.debugging.Assert(condition=tf.abs(rootRadicands) > 1e-5,data=rootRadicands)\n",
    "        \n",
    "    vecPlus = tf.math.l2_normalize(vecPlus,epsilon=1e-5)\n",
    "    vecMinus = tf.math.l2_normalize(vecMinus,epsilon=1e-5)\n",
    "    return ((valPlus,valMinus),(vecPlus,vecMinus))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "U = tf.random.normal((1,2))\n",
    "V = tf.random.normal((1,2))\n",
    "eigvals,eigvecs = eigvecReversal(U,V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-1.8185118   0.5211488 ]\n",
      "  [ 0.5211488   0.77038383]]], shape=(1, 2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[-1.8185118  0.5211488]\n",
      "  [ 0.5211488  0.7703838]]], shape=(1, 2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "A = OuterProd()(U,V) + OuterProd()(V,U)\n",
    "print(A)\n",
    "A_again = eigvals[0]*OuterProd()(eigvecs[0],eigvecs[0]) + eigvals[1]*OuterProd()(eigvecs[1],eigvecs[1])\n",
    "print(A_again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5707 - val_loss: 0.4725\n",
      "Epoch 2/16\n",
      "100/100 [==============================] - 0s 870us/step - loss: 0.4767 - val_loss: 0.4467\n",
      "Epoch 3/16\n",
      "100/100 [==============================] - 0s 914us/step - loss: 0.3792 - val_loss: 0.2067\n",
      "Epoch 4/16\n",
      "100/100 [==============================] - 0s 907us/step - loss: 0.0652 - val_loss: 0.0039\n",
      "Epoch 5/16\n",
      "100/100 [==============================] - 0s 852us/step - loss: 9.5699e-04 - val_loss: 6.3413e-05\n",
      "Epoch 6/16\n",
      "100/100 [==============================] - 0s 808us/step - loss: 1.7138e-05 - val_loss: 1.2715e-06\n",
      "Epoch 7/16\n",
      "100/100 [==============================] - 0s 846us/step - loss: 3.4603e-07 - val_loss: 2.5757e-08\n",
      "Epoch 8/16\n",
      "100/100 [==============================] - 0s 808us/step - loss: 7.0086e-09 - val_loss: 5.2393e-10\n",
      "Epoch 9/16\n",
      "100/100 [==============================] - 0s 872us/step - loss: 1.4275e-10 - val_loss: 1.0633e-11\n",
      "Epoch 10/16\n",
      "100/100 [==============================] - 0s 814us/step - loss: 2.9106e-12 - val_loss: 2.3571e-13\n",
      "Epoch 11/16\n",
      "100/100 [==============================] - 0s 823us/step - loss: 7.5229e-14 - val_loss: 2.3267e-14\n",
      "Epoch 12/16\n",
      "100/100 [==============================] - 0s 887us/step - loss: 1.5916e-14 - val_loss: 1.5565e-14\n",
      "Epoch 13/16\n",
      "100/100 [==============================] - 0s 855us/step - loss: 1.4542e-14 - val_loss: 1.5192e-14\n",
      "Epoch 14/16\n",
      "100/100 [==============================] - 0s 828us/step - loss: 1.4370e-14 - val_loss: 1.5192e-14\n",
      "Epoch 15/16\n",
      "100/100 [==============================] - 0s 808us/step - loss: 1.4398e-14 - val_loss: 1.5195e-14\n",
      "Epoch 16/16\n",
      "100/100 [==============================] - 0s 844us/step - loss: 1.4348e-14 - val_loss: 1.5194e-14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'new_matrix_and_vector/Variable:0' shape=(1, 2) dtype=float32, numpy=array([[ 1.1247319e-08, -9.9999994e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "class NewMatrixAndVector(MatrixAndVector):\n",
    "    def build(self,input_shape):\n",
    "        super().build(input_shape)\n",
    "    def setupA(self,input_shape,V):\n",
    "        idmat = tf.eye(num_rows=input_shape[-1],batch_shape=(1,) + input_shape[1:-1],dtype=self.dtype)\n",
    "        self.A = tf.Variable(initial_value = idmat + OuterProd(dtype=self.dtype)(self.V,self.V), trainable = False)\n",
    "    def applyA(self,x):\n",
    "        return tf.linalg.matvec(self.A,x)\n",
    "\n",
    "v_init = np.zeros(shape=(1,2))\n",
    "v_init[slice(None),0] = 1\n",
    "\n",
    "ApVVh= NewMatrixAndVector(v_init)\n",
    "                             \n",
    "x = tf.keras.layers.Input((2,))\n",
    "y = ApVVh(x)\n",
    "model = CustomTrainModel(x,y)\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(),loss=tf.keras.losses.MeanSquaredError(),run_eagerly=False)\n",
    "\n",
    "x_train=np.random.randn(1000,2)\n",
    "y_train = 2*x_train\n",
    "x_val=np.random.randn(100,2)\n",
    "y_val = 2*x_val\n",
    "model.fit(x=x_train,y=y_train,batch_size=10,epochs=16,validation_data=(x_val,y_val))\n",
    "ApVVh.V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "in user code:\n\n    /home/lrr/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /home/lrr/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/lrr/anaconda3/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/lrr/anaconda3/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/lrr/anaconda3/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/lrr/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    <ipython-input-3-2a29dd52d3f3>:8 train_step\n        PostProcess.update[tv.name]()\n    <ipython-input-4-018dd40a6d6e>:22 post_update\n        eigvals, eigvecs = eigvecReversal(U,self.Vfixed)\n\n    NameError: name 'eigvecReversal' is not defined\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-018dd40a6d6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0mApVVh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lrr/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lrr/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lrr/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lrr/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lrr/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 697\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lrr/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lrr/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lrr/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lrr/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lrr/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lrr/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: in user code:\n\n    /home/lrr/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /home/lrr/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/lrr/anaconda3/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/lrr/anaconda3/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/lrr/anaconda3/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/lrr/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    <ipython-input-3-2a29dd52d3f3>:8 train_step\n        PostProcess.update[tv.name]()\n    <ipython-input-4-018dd40a6d6e>:22 post_update\n        eigvals, eigvecs = eigvecReversal(U,self.Vfixed)\n\n    NameError: name 'eigvecReversal' is not defined\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "class NewMatrixAndVector(MatrixAndVector,PostProcess):\n",
    "    def build(self,input_shape):\n",
    "        super().build(input_shape)\n",
    "        self.Vfixed = tf.Variable(initial_value=tf.identity(self.V),trainable=False,dtype=self.dtype)\n",
    "        PostProcess.update[self.V.name] = self.post_update\n",
    "    def setupA(self,input_shape,V):\n",
    "        idmat = tf.eye(num_rows=input_shape[-1],batch_shape=(1,) + input_shape[1:-1],dtype=self.dtype)\n",
    "        self.A = tf.Variable(initial_value = idmat + OuterProd(dtype=self.dtype)(self.V,self.V), trainable = False)\n",
    "    def applyA(self,x):\n",
    "        return tf.linalg.matvec(self.A,x)\n",
    "    def updateA(self,u_vec,mult):\n",
    "        return self.A.assign(self.A + mult*OuterProd(dtype=self.dtype)(u_vec,u_vec))\n",
    "    def post_update(self):\n",
    "        U = self.V - self.Vfixed\n",
    "        with tf.control_dependencies([U]):\n",
    "            self.V.assign(self.Vfixed)\n",
    "        newA = self.updateA(U,1.0)\n",
    "        eigvals, eigvecs = eigvecReversal(U,self.Vfixed)\n",
    "        for ii in range(2):\n",
    "            with tf.control_dependencies([newA]):\n",
    "                newA = self.updateA(eigvecs[ii],eigvals[ii])\n",
    "\n",
    "v_init = np.zeros(shape=(1,2))\n",
    "v_init[slice(None),0] = 1\n",
    "\n",
    "ApVVh= NewMatrixAndVector(v_init)\n",
    "                             \n",
    "x = tf.keras.layers.Input((2,))\n",
    "y = ApVVh(x)\n",
    "model = CustomTrainModel(x,y)\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(0.2),loss=tf.keras.losses.MeanSquaredError(),run_eagerly=False)\n",
    "\n",
    "x_train=np.random.randn(1000,2)\n",
    "y_train = 2*x_train\n",
    "x_val=np.random.randn(100,2)\n",
    "y_val = 2*x_val\n",
    "model.fit(x=x_train,y=y_train,batch_size=10,epochs=16,validation_data=(x_val,y_val))\n",
    "ApVVh.V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NewMatrixAndVector' object has no attribute 'A'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-8f83398caf5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mApVVh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NewMatrixAndVector' object has no attribute 'A'"
     ]
    }
   ],
   "source": [
    "print(ApVVh.A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.3534 - val_loss: 0.1727\n",
      "Epoch 2/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1708 - val_loss: 0.0833\n",
      "Epoch 3/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0863 - val_loss: 0.0519\n",
      "Epoch 4/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0542 - val_loss: 0.0309\n",
      "Epoch 5/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0351 - val_loss: 0.0223\n",
      "Epoch 6/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0255 - val_loss: 0.0164\n",
      "Epoch 7/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0125\n",
      "Epoch 8/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0105\n",
      "Epoch 9/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0087\n",
      "Epoch 10/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0079\n",
      "Epoch 11/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.0071\n",
      "Epoch 12/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0063\n",
      "Epoch 13/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0058\n",
      "Epoch 14/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0050\n",
      "Epoch 15/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0047\n",
      "Epoch 16/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'new_matrix_and_vector_49/Variable:0' shape=(1, 2) dtype=float32, numpy=array([[1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "class NewMatrixAndVector(MatrixAndVector,PostProcess):\n",
    "    def build(self,input_shape):\n",
    "        super().build(input_shape)\n",
    "        self.Vfixed = tf.Variable(initial_value=tf.identity(self.V),trainable=False,dtype=self.dtype)\n",
    "        PostProcess.update[self.V.name] = self.post_update\n",
    "    def updateA(self,u_vec,mult):\n",
    "        return self.L.assign(tfp.math.cholesky_update(self.L,update_vector=u_vec,multiplier=mult))\n",
    "    def post_update(self):\n",
    "        U = self.V - self.Vfixed\n",
    "        #print(U)\n",
    "        with tf.control_dependencies([U]):\n",
    "            self.V.assign(self.Vfixed)\n",
    "        newA = self.updateA(U,1.0)\n",
    "        #print(tf.matmul(newA,newA,adjoint_b=True))\n",
    "        eigvals, eigvecs = eigvecReversal(U,self.Vfixed)\n",
    "        for ii in range(2):\n",
    "            with tf.control_dependencies([newA]):\n",
    "                newA = self.updateA(eigvecs[ii],eigvals[ii])\n",
    "\n",
    "v_init = np.zeros((1,2))\n",
    "b = np.zeros(shape=(1,2))\n",
    "b[slice(None),0] = 1\n",
    "v_init[slice(None),0] = 1\n",
    "\n",
    "ApVVh= NewMatrixAndVector(v_init)\n",
    "                             \n",
    "x = tf.keras.layers.Input((2,))\n",
    "y = ApVVh(x)\n",
    "model = CustomTrainModel(x,y)\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(0.2),loss=tf.keras.losses.MeanSquaredError(),run_eagerly=False)\n",
    "\n",
    "x_train=np.random.randn(1000,2)\n",
    "y_train = 2*x_train\n",
    "x_val=np.random.randn(100,2)\n",
    "y_val = 2*x_val\n",
    "model.fit(x=x_train,y=y_train,batch_size=10,epochs=16,validation_data=(x_val,y_val))\n",
    "ApVVh.V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[1.00850006+0.j         0.0021042 +0.00019345j]\n",
      "  [0.0021042 -0.00019345j 1.34594523+0.j        ]]], shape=(1, 2, 2), dtype=complex128)\n"
     ]
    }
   ],
   "source": [
    "print(tf.linalg.matmul(ApVVh.L,ApVVh.L,adjoint_b=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def complexNum(x):\n",
    "    return tf.complex(x,tf.cast(0.0,dtype = x.dtype))\n",
    "\n",
    "def eigvecReversal(U,V):\n",
    "    vhv = tf.reduce_sum(tf.math.conj(V)*V,axis=-1,keepdims=True)\n",
    "    uhu = tf.reduce_sum(tf.math.conj(U)*U,axis=-1,keepdims=True)\n",
    "    uhv = tf.reduce_sum(tf.math.conj(U)*V,axis=-1,keepdims=True)\n",
    "    rootRadicand = tf.math.sqrt(vhv*uhu - complexNum(tf.math.imag(uhv)**2))\n",
    "        \n",
    "    valPlus = complexNum(tf.math.real(uhv)) + rootRadicand\n",
    "    valMinus = complexNum(tf.math.real(uhv)) - rootRadicand\n",
    "    vecPlus = vhv*U + (1j*complexNum(tf.math.imag(uhv)) + rootRadicand)*V\n",
    "    vecMinus = vhv*U + (1j*complexNum(tf.math.imag(uhv))  - rootRadicand)*V\n",
    "    vecPlus = tf.where(tf.abs(rootRadicand) > 1e-5,vecPlus,U)\n",
    "    vecMinus = tf.where(tf.abs(rootRadicand) > 1e-5,vecMinus,-tf.math.divide_no_nan(uhv,uhu)*U + V)\n",
    "    #tf.debugging.Assert(condition=tf.abs(rootRadicands) > 1e-5,data=rootRadicands)\n",
    "        \n",
    "    vecPlus = tf.math.l2_normalize(vecPlus,epsilon=1e-5)\n",
    "    vecMinus = tf.math.l2_normalize(vecMinus,epsilon=1e-5)\n",
    "    valPlus = tf.reshape(valPlus,valPlus.shape[:-1])\n",
    "    valMinus = tf.reshape(valMinus,valMinus.shape[:-1])\n",
    "    return ((valPlus,valMinus),(vecPlus,vecMinus))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "U = tf.complex(tf.random.normal((1,2)),tf.random.normal((1,2)))\n",
    "V = tf.complex(tf.random.normal((1,2)),tf.random.normal((1,2)))\n",
    "eigvals,eigvecs = eigvecReversal(U,V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 1.3619424 +0.j         -0.34927106+0.65208745j]\n",
      "  [-0.34927106-0.65208745j -0.63275087+0.j        ]]], shape=(1, 2, 2), dtype=complex64)\n",
      "tf.Tensor(\n",
      "[[[ 1.3619424 +0.j        -0.34927112+0.6520874j]\n",
      "  [-0.34927112-0.6520874j -0.632751  +0.j       ]]], shape=(1, 2, 2), dtype=complex64)\n"
     ]
    }
   ],
   "source": [
    "A = OuterProd()(U,V) + OuterProd()(V,U)\n",
    "print(A)\n",
    "A_again = eigvals[0]*OuterProd()(eigvecs[0],eigvecs[0]) + eigvals[1]*OuterProd()(eigvecs[1],eigvecs[1])\n",
    "print(A_again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def complexNum(x):\n",
    "    return tf.complex(x,tf.cast(0.0,dtype = x.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6812 - val_loss: 0.4378\n",
      "Epoch 2/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.3425 - val_loss: 0.2508\n",
      "Epoch 3/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1965 - val_loss: 0.1550\n",
      "Epoch 4/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1315 - val_loss: 0.1147\n",
      "Epoch 5/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0983 - val_loss: 0.0826\n",
      "Epoch 6/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0740 - val_loss: 0.0628\n",
      "Epoch 7/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0572 - val_loss: 0.0493\n",
      "Epoch 8/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0451 - val_loss: 0.0398\n",
      "Epoch 9/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0368 - val_loss: 0.0326\n",
      "Epoch 10/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0308 - val_loss: 0.0286\n",
      "Epoch 11/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0265 - val_loss: 0.0243\n",
      "Epoch 12/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0229 - val_loss: 0.0211\n",
      "Epoch 13/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0188\n",
      "Epoch 14/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0165\n",
      "Epoch 15/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0149\n",
      "Epoch 16/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0132\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'new_matrix_and_vector/Variable:0' shape=(1, 2) dtype=complex128, numpy=array([[1.+0.j, 0.+0.j]])>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tf_rewrites as tfp\n",
    "class NewMatrixAndVector(MatrixAndVector,PostProcess):\n",
    "    def build(self,input_shape):\n",
    "        super().build(input_shape)\n",
    "        self.Vfixed = tf.Variable(initial_value=tf.identity(self.V),trainable=False,dtype=self.dtype)\n",
    "        PostProcess.update[self.V.name] = self.post_update\n",
    "    def updateA(self,u_vec,mult):\n",
    "        return self.L.assign(tfp.cholesky_update(self.L,update_vector=u_vec,multiplier=mult))\n",
    "    def post_update(self):\n",
    "        U = self.V - self.Vfixed\n",
    "        with tf.control_dependencies([U]):\n",
    "            self.V.assign(self.Vfixed)\n",
    "        newA = self.updateA(U,1.0)\n",
    "        eigvals, eigvecs = eigvecReversal(U,self.Vfixed)\n",
    "        for ii in range(2):\n",
    "            with tf.control_dependencies([newA]):\n",
    "                newA = self.updateA(eigvecs[ii],eigvals[ii])\n",
    "\n",
    "v_a = np.zeros((1,2))\n",
    "v_a[slice(None),0] = 1\n",
    "v_b = np.zeros(shape=(1,2))\n",
    "#v_b[slice(None),1] = 0.5\n",
    "v_init = tf.complex(v_a,v_b)\n",
    "\n",
    "ApVVh= NewMatrixAndVector(v_init,dtype=tf.complex128)\n",
    "\n",
    "                             \n",
    "x = tf.keras.layers.Input((2,),dtype = tf.complex128)\n",
    "y = ApVVh(x)\n",
    "model = CustomTrainModel(x,y)\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(.1),loss=tf.keras.losses.MeanSquaredError(),run_eagerly=False)\n",
    "\n",
    "x_train=np.random.randn(1000,2) + 1j*np.random.randn(1000,2)\n",
    "y_train = 2*x_train\n",
    "x_val=np.random.randn(100,2) + 1j*np.random.randn(100,2)\n",
    "y_val = 2*x_val\n",
    "model.fit(x=x_train,y=y_train,batch_size=10,epochs=16,validation_data=(x_val,y_val))\n",
    "ApVVh.V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import tf_rewrites as tfr\n",
    "rho = 1.\n",
    "x_shape = (4,3,5,5)\n",
    "dtype = tf.complex128\n",
    "def cmplx_normal(x_shape,dtype):\n",
    "    return tf.complex(tf.random.normal(x_shape,dtype=dtype.real_dtype),tf.random.normal(x_shape,dtype=dtype.real_dtype))\n",
    "x = cmplx_normal(x_shape,dtype)\n",
    "idmat = tf.eye(num_rows=x_shape[-1],batch_shape = x_shape[:2],dtype= dtype)\n",
    "A = rho*idmat + tf.linalg.matmul(x,x,adjoint_b=True)\n",
    "v = cmplx_normal(x_shape[:-1],dtype)\n",
    "m = tf.complex(0.*tf.random.normal((4,3,),dtype=dtype.real_dtype) + 1.,0.*tf.random.normal((4,3),dtype=dtype.real_dtype))\n",
    "\n",
    "L = tf.linalg.cholesky(A)\n",
    "L2 = tfr.cholesky_update(L,v,m)\n",
    "L3 = tfp.math.cholesky_update(L,v,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addDim(x):\n",
    "    return tf.reshape(x,x.shape + (1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3.552713678800501e-15, shape=(), dtype=float64)\n",
      "tf.Tensor(5.329070518200751e-15, shape=(), dtype=float64)\n",
      "tf.Tensor(28.918581336141166, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(tf.reduce_max(tf.abs(A - tf.linalg.matmul(L,L,adjoint_b=True))))\n",
    "A2 = A + addDim(addDim(m))*tf.linalg.matmul(addDim(v),addDim(v),adjoint_b=True)\n",
    "print(tf.reduce_max(tf.abs(A2 - tf.linalg.matmul(L2,L2,adjoint_b=True))))\n",
    "print(tf.reduce_max(tf.abs(A2 - tf.linalg.matmul(L3,L3,adjoint_b=True))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4, 2)\n",
      "(3, 4, 2, 6)\n",
      "tf.Tensor(3.552713678800501e-15, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matrix_decompositions_tf as fctr\n",
    "def cmplx_normal(x_shape,dtype):\n",
    "    return tf.complex(tf.random.normal(x_shape,dtype=dtype.real_dtype),tf.random.normal(x_shape,dtype=dtype.real_dtype))\n",
    "def addDim(x):\n",
    "    return tf.reshape(x,x.shape + (1,))\n",
    "\n",
    "\n",
    "v_shape = (3,4,2,6)\n",
    "dtype = tf.complex128\n",
    "\n",
    "u = cmplx_normal(v_shape,dtype)\n",
    "v = cmplx_normal(v_shape,dtype)\n",
    "\n",
    "eigvals,eigvecs = fctr.rank2eigen(u,v)\n",
    "print(eigvals[0].shape)\n",
    "print(eigvecs[0].shape)\n",
    "\n",
    "eigsum = 0.\n",
    "for val,vec in zip(eigvals,eigvecs):\n",
    "    eigsum = eigsum + addDim(addDim(val))*tf.linalg.matmul(addDim(vec),addDim(vec),adjoint_b=True)\n",
    "\n",
    "straightSum = tf.linalg.matmul(addDim(u),addDim(v),adjoint_b = True) + tf.linalg.matmul(addDim(v),addDim(u),adjoint_b=True)\n",
    "\n",
    "print(tf.reduce_max(tf.abs(eigsum - straightSum)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4, 2, 1), dtype=complex128, numpy=\n",
       "array([[[[0.12376822+0.j],\n",
       "         [0.20984116+0.j]],\n",
       "\n",
       "        [[0.02174207+0.j],\n",
       "         [0.0400276 +0.j]],\n",
       "\n",
       "        [[0.02745349+0.j],\n",
       "         [0.02636881+0.j]],\n",
       "\n",
       "        [[0.06287725+0.j],\n",
       "         [0.00775799+0.j]]],\n",
       "\n",
       "\n",
       "       [[[0.12664901+0.j],\n",
       "         [0.00206361+0.j]],\n",
       "\n",
       "        [[0.01370283+0.j],\n",
       "         [0.04698159+0.j]],\n",
       "\n",
       "        [[0.02298322+0.j],\n",
       "         [0.04410531+0.j]],\n",
       "\n",
       "        [[0.01009955+0.j],\n",
       "         [0.02290069+0.j]]],\n",
       "\n",
       "\n",
       "       [[[0.00745083+0.j],\n",
       "         [0.0144493 +0.j]],\n",
       "\n",
       "        [[0.02748401+0.j],\n",
       "         [0.02219594+0.j]],\n",
       "\n",
       "        [[0.04715586+0.j],\n",
       "         [0.03141533+0.j]],\n",
       "\n",
       "        [[0.03774115+0.j],\n",
       "         [0.00278519+0.j]]]])>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(eigvecs[0]*tf.math.conj(eigvecs[0]),axis=-1,keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
