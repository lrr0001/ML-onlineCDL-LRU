{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to add post-processing after the gradient updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def custom_loss(y_actual, y_pred):\n",
    "    pred_rank = tf.rank(y_pred)\n",
    "    if pred_rank > 1:\n",
    "        return tf.math.reduce_sum(1/((y_actual - y_pred - 1)**2 + 0.6) - 1/((y_actual - y_pred + 1)**2 + 0.6),axis=tf.range(1,tf.rank(y_pred)))\n",
    "    else:\n",
    "        return 1/((y_actual - y_pred - 1)**2 + 0.6) - 1/((y_actual - y_pred + 1)**2 + 0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The custom loss function is minimized when the model predicts an output 1 larger than the actual (ground truth) output. The loss function is maximized when the model predicts 1 less than actual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "y_actual = np.arange(-2,2,0.05)\n",
    "y_predicted = np.zeros(y_actual.shape)\n",
    "\n",
    "fig = plt.figure()\n",
    "axs = fig.add_axes([0,0,1,1])\n",
    "#loss = lambda act,pred: np.array([custom_loss(act[ii],pred[ii]) for ii in range(act.shape[0])])\n",
    "\n",
    "axs.plot(y_predicted - y_actual,custom_loss(y_actual,y_predicted))\n",
    "axs.set_title('Custom Loss Function')\n",
    "axs.set_ylabel('Loss')\n",
    "axs.set_xlabel('Predicted Minus Actual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, there is no post gradient computations. The network correctly finds that by adding 1 to the input, the loss is minimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "100/100 [==============================] - 0s 2ms/step - loss: -0.0909 - val_loss: -0.1713\n",
      "Epoch 2/16\n",
      "100/100 [==============================] - 0s 810us/step - loss: -0.2503 - val_loss: -0.3316\n",
      "Epoch 3/16\n",
      "100/100 [==============================] - 0s 939us/step - loss: -0.4130 - val_loss: -0.4971\n",
      "Epoch 4/16\n",
      "100/100 [==============================] - 0s 877us/step - loss: -0.5815 - val_loss: -0.6684\n",
      "Epoch 5/16\n",
      "100/100 [==============================] - 0s 804us/step - loss: -0.7549 - val_loss: -0.8434\n",
      "Epoch 6/16\n",
      "100/100 [==============================] - 0s 825us/step - loss: -0.9295 - val_loss: -1.0162\n",
      "Epoch 7/16\n",
      "100/100 [==============================] - 0s 825us/step - loss: -1.0971 - val_loss: -1.1765\n",
      "Epoch 8/16\n",
      "100/100 [==============================] - 0s 873us/step - loss: -1.2456 - val_loss: -1.3105\n",
      "Epoch 9/16\n",
      "100/100 [==============================] - 0s 913us/step - loss: -1.3606 - val_loss: -1.4039\n",
      "Epoch 10/16\n",
      "100/100 [==============================] - 0s 958us/step - loss: -1.4299 - val_loss: -1.4478\n",
      "Epoch 11/16\n",
      "100/100 [==============================] - 0s 856us/step - loss: -1.4516 - val_loss: -1.4524\n",
      "Epoch 12/16\n",
      "100/100 [==============================] - 0s 958us/step - loss: -1.4524 - val_loss: -1.4524\n",
      "Epoch 13/16\n",
      "100/100 [==============================] - 0s 928us/step - loss: -1.4524 - val_loss: -1.4524\n",
      "Epoch 14/16\n",
      "100/100 [==============================] - 0s 830us/step - loss: -1.4524 - val_loss: -1.4524\n",
      "Epoch 15/16\n",
      "100/100 [==============================] - 0s 874us/step - loss: -1.4524 - val_loss: -1.4524\n",
      "Epoch 16/16\n",
      "100/100 [==============================] - 0s 828us/step - loss: -1.4524 - val_loss: -1.4524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'add_var/Variable:0' shape=(1,) dtype=float32, numpy=array([1.0322956], dtype=float32)>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class AddVar(tf.keras.layers.Layer):\n",
    "    def __init__(*args,**kwargs):\n",
    "        tf.keras.layers.Layer.__init__(*args,**kwargs)\n",
    "    def build(self,input_shape):\n",
    "        self.bias = tf.Variable(initial_value=tf.zeros(input_shape[-1]),trainable=True,dtype=self.dtype)\n",
    "    def call(self,inputs):\n",
    "        return inputs + self.bias\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(1,))\n",
    "outputs = AddVar()(inputs)\n",
    "model = tf.keras.Model(inputs,outputs)\n",
    "model.compile(loss = custom_loss)\n",
    "x = np.random.randn(1000,1)\n",
    "y = x\n",
    "xval = np.random.randn(100,1)\n",
    "yval = xval\n",
    "model.fit(x=x,y=y,batch_size=10,epochs=16,validation_data = (xval,yval))\n",
    "model.trainable_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, this example demonstrates adding a post-gradient process.  The post-gradient process takes the update and reverses its sign, effectively changing the algorithm to gradient ascent. As a result, Tensorflow ends up maximizing the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class PostProcess:\n",
    "    update = {}\n",
    "    def add_update(varName,update_fun):\n",
    "        assert varName not in PostProcess.update, \"Update function already exists for %r; may be duplicate\" % varName\n",
    "        PostProcess.update[varName] = update_fun\n",
    "\n",
    "\n",
    "class AddVar(tf.keras.layers.Layer,PostProcess):\n",
    "    def __init__(*args,**kwargs):\n",
    "        tf.keras.layers.Layer.__init__(*args,**kwargs)\n",
    "    def build(self,input_shape):\n",
    "        self.bias = tf.Variable(initial_value=tf.zeros(input_shape[-1]),trainable=False,dtype=self.dtype)\n",
    "        self.bias2 = tf.Variable(initial_value=tf.identity(self.bias),trainable=True,dtype=self.dtype)\n",
    "        PostProcess.add_update(self.bias2.name, self.post_update)\n",
    "    def call(self,inputs):\n",
    "        return inputs + self.bias2\n",
    "    def post_update(self):\n",
    "\n",
    "        theupdate = self.bias2 - self.bias\n",
    "        # If \"=\" is used for assignment, differentiation will fail (in eager execution) or throw an error.\n",
    "        # The assign operator is required.        \n",
    "        newBias2 = self.bias2.assign(self.bias - theupdate)\n",
    "        return [self.bias.assign(newBias2)]\n",
    "\n",
    "class CustomTrainModel(tf.keras.Model):\n",
    "    def train_step(self,data):\n",
    "        myoutputs = tf.keras.Model.train_step(self,data)\n",
    "        for tv in self.trainable_variables:\n",
    "            if tv.name in PostProcess.update:\n",
    "                PostProcess.update[tv.name]()\n",
    "        return myoutputs\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(1,))\n",
    "outputs = AddVar()(inputs)\n",
    "model = CustomTrainModel(inputs,outputs)\n",
    "model.compile(loss = custom_loss,run_eagerly=False)\n",
    "x = np.random.randn(1000,1)\n",
    "y = x\n",
    "xval = np.random.randn(100,1)\n",
    "yval = xval\n",
    "model.fit(x=x,y=y,batch_size=10,epochs=16,validation_data = (xval,yval))\n",
    "model.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('test_save_output.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
